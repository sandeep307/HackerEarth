{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from hyperopt import hp\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "import sys\n",
    "import xgboost as xgb\n",
    "import datetime\n",
    "import time\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>DetectedCamera</th>\n",
       "      <th>AngleOfSign</th>\n",
       "      <th>SignAspectRatio</th>\n",
       "      <th>SignWidth</th>\n",
       "      <th>SignHeight</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2c9180975a056a64015a1e0a52e57021</td>\n",
       "      <td>3</td>\n",
       "      <td>195</td>\n",
       "      <td>1.02</td>\n",
       "      <td>46</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2c9180975a056a64015a1e17b32171e4</td>\n",
       "      <td>3</td>\n",
       "      <td>203</td>\n",
       "      <td>1.09</td>\n",
       "      <td>59</td>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2c9180975a056a64015a1de4deb16bd5</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0.96</td>\n",
       "      <td>104</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2c9180975a056a64015a1de4deb16bdd</td>\n",
       "      <td>3</td>\n",
       "      <td>199</td>\n",
       "      <td>0.81</td>\n",
       "      <td>38</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2c9180975a056a64015a1de4deb16bd6</td>\n",
       "      <td>3</td>\n",
       "      <td>208</td>\n",
       "      <td>0.93</td>\n",
       "      <td>54</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  DetectedCamera  AngleOfSign  \\\n",
       "0  2c9180975a056a64015a1e0a52e57021               3          195   \n",
       "1  2c9180975a056a64015a1e17b32171e4               3          203   \n",
       "2  2c9180975a056a64015a1de4deb16bd5               0           26   \n",
       "3  2c9180975a056a64015a1de4deb16bdd               3          199   \n",
       "4  2c9180975a056a64015a1de4deb16bd6               3          208   \n",
       "\n",
       "   SignAspectRatio  SignWidth  SignHeight  Target  \n",
       "0             1.02         46          45       2  \n",
       "1             1.09         59          54       2  \n",
       "2             0.96        104         108       0  \n",
       "3             0.81         38          47       2  \n",
       "4             0.93         54          58       2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "ids = test.Id\n",
    "\n",
    "mapping = {'Front':0, 'Right':1, 'Left':2, 'Rear':3}\n",
    "train = train.replace({'DetectedCamera':mapping})\n",
    "test = test.replace({'DetectedCamera':mapping})\n",
    "\n",
    "#renaming column\n",
    "train.rename(columns = {'SignFacing (Target)': 'Target'}, inplace=True)\n",
    "\n",
    "#encode Target Variable based on sample submission file\n",
    "mapping = {'Front':0, 'Left':1, 'Rear':2, 'Right':3}\n",
    "train = train.replace({'Target':mapping})\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>DetectedCamera</th>\n",
       "      <th>AngleOfSign</th>\n",
       "      <th>SignAspectRatio</th>\n",
       "      <th>SignWidth</th>\n",
       "      <th>SignHeight</th>\n",
       "      <th>Target</th>\n",
       "      <th>SignArea</th>\n",
       "      <th>SignPeri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2c9180975a056a64015a1e0a52e57021</td>\n",
       "      <td>3</td>\n",
       "      <td>195</td>\n",
       "      <td>1.02</td>\n",
       "      <td>46</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>2070</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2c9180975a056a64015a1e17b32171e4</td>\n",
       "      <td>3</td>\n",
       "      <td>203</td>\n",
       "      <td>1.09</td>\n",
       "      <td>59</td>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>3186</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2c9180975a056a64015a1de4deb16bd5</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0.96</td>\n",
       "      <td>104</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>11232</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2c9180975a056a64015a1de4deb16bdd</td>\n",
       "      <td>3</td>\n",
       "      <td>199</td>\n",
       "      <td>0.81</td>\n",
       "      <td>38</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>1786</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2c9180975a056a64015a1de4deb16bd6</td>\n",
       "      <td>3</td>\n",
       "      <td>208</td>\n",
       "      <td>0.93</td>\n",
       "      <td>54</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>3132</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  DetectedCamera  AngleOfSign  \\\n",
       "0  2c9180975a056a64015a1e0a52e57021               3          195   \n",
       "1  2c9180975a056a64015a1e17b32171e4               3          203   \n",
       "2  2c9180975a056a64015a1de4deb16bd5               0           26   \n",
       "3  2c9180975a056a64015a1de4deb16bdd               3          199   \n",
       "4  2c9180975a056a64015a1de4deb16bd6               3          208   \n",
       "\n",
       "   SignAspectRatio  SignWidth  SignHeight  Target  SignArea  SignPeri  \n",
       "0             1.02         46          45       2      2070        91  \n",
       "1             1.09         59          54       2      3186       113  \n",
       "2             0.96        104         108       0     11232       212  \n",
       "3             0.81         38          47       2      1786        85  \n",
       "4             0.93         54          58       2      3132       112  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['SignArea'] = train['SignWidth'] * train['SignHeight']\n",
    "test['SignArea'] = test['SignWidth'] * test['SignHeight']\n",
    "train['SignPeri'] = train['SignWidth'] + train['SignHeight']\n",
    "test['SignPeri'] = test['SignWidth'] + test['SignHeight']\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = train['Target']\n",
    "train = train.drop(['Target', 'Id'], axis=1)\n",
    "test.drop('Id',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(params):\n",
    "    print (\"Training with params : \")\n",
    "    print (params)\n",
    "    num_round = int(params['n_estimators'])\n",
    "    del params['n_estimators']\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dvalid = xgb.DMatrix(X_test, label=y_test)\n",
    "    # watchlist = [(dvalid, 'eval'), (dtrain, 'train')]\n",
    "    model = xgb.train(params, dtrain, num_round)\n",
    "    predictions = model.predict(dvalid)\n",
    "    score =   log_loss( y_test, predictions) \n",
    "    print (\"\\tScore {0}\\n\\n\".format(score))\n",
    "    return {'loss': score, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize(trials):\n",
    "    space = {\n",
    "             'n_estimators' : hp.quniform('n_estimators', 100, 1500, 1),\n",
    "             'eta' : hp.quniform('eta', 0.025, 0.5, 0.025),\n",
    "             'max_depth' : hp.choice('max_depth', np.arange(1, 13, dtype=int)),\n",
    "             'min_child_weight' : hp.quniform('min_child_weight', 1, 6, 1), \n",
    "             'subsample' : hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "             'alpha' : hp.quniform('alpha', 0, 1, 0.05),\n",
    "             'gamma' : hp.quniform('gamma', 0.5, 1, 0.05),\n",
    "             'colsample_bytree' : hp.quniform('colsample_bytree', 0.5, 1, 0.05),\n",
    "             'eval_metric': 'mlogloss',\n",
    "             'objective': 'multi:softprob',\n",
    "             'num_class' : 4,\n",
    "             'nthread' : 6,\n",
    "             'silent' : 1\n",
    "             }\n",
    "\n",
    "    best = fmin(score, space, algo=tpe.suggest, trials=trials, max_evals= 500)\n",
    "    print (best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data into train and valid ...\n",
      "\n",
      "\n",
      "(30788, 7) (7697, 7) (30788,) (7697,)\n"
     ]
    }
   ],
   "source": [
    "X, y = train, target\n",
    "print (\"Splitting data into train and valid ...\\n\\n\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=1234)\n",
    "print (X_train.shape, X_test.shape, y_train.shape, y_test.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 882.0, 'eval_metric': 'mlogloss', 'eta': 0.47500000000000003, 'nthread': 6, 'colsample_bytree': 0.8, 'max_depth': 3, 'alpha': 0.35000000000000003, 'min_child_weight': 4.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.11924749069079894\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 713.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 10, 'alpha': 0.55, 'min_child_weight': 2.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.12408606705082673\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 1475.0, 'eval_metric': 'mlogloss', 'eta': 0.17500000000000002, 'nthread': 6, 'colsample_bytree': 0.55, 'max_depth': 8, 'alpha': 0.05, 'min_child_weight': 5.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.13209154663830455\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 1493.0, 'eval_metric': 'mlogloss', 'eta': 0.15000000000000002, 'nthread': 6, 'colsample_bytree': 0.55, 'max_depth': 12, 'alpha': 0.15000000000000002, 'min_child_weight': 5.0, 'gamma': 0.6000000000000001, 'silent': 1}\n",
      "\tScore 0.14354322028206304\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9, 'n_estimators': 243.0, 'eval_metric': 'mlogloss', 'eta': 0.17500000000000002, 'nthread': 6, 'colsample_bytree': 0.65, 'max_depth': 8, 'alpha': 0.2, 'min_child_weight': 5.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.11583270396002503\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9, 'n_estimators': 222.0, 'eval_metric': 'mlogloss', 'eta': 0.35000000000000003, 'nthread': 6, 'colsample_bytree': 0.75, 'max_depth': 12, 'alpha': 0.9500000000000001, 'min_child_weight': 2.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.11858034393232898\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.55, 'n_estimators': 872.0, 'eval_metric': 'mlogloss', 'eta': 0.225, 'nthread': 6, 'colsample_bytree': 0.65, 'max_depth': 7, 'alpha': 0.65, 'min_child_weight': 4.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.12921697358015308\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8500000000000001, 'n_estimators': 1226.0, 'eval_metric': 'mlogloss', 'eta': 0.35000000000000003, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 12, 'alpha': 0.25, 'min_child_weight': 4.0, 'gamma': 0.65, 'silent': 1}\n",
      "\tScore 0.14133739948544705\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 889.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 0.7000000000000001, 'max_depth': 4, 'alpha': 0.8, 'min_child_weight': 6.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.11249740971721814\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.55, 'n_estimators': 1137.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 0.75, 'max_depth': 7, 'alpha': 0.8, 'min_child_weight': 2.0, 'gamma': 0.5, 'silent': 1}\n",
      "\tScore 0.12210431622782397\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 390.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 0.8, 'max_depth': 3, 'alpha': 0.8500000000000001, 'min_child_weight': 3.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.1089040144768658\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8500000000000001, 'n_estimators': 320.0, 'eval_metric': 'mlogloss', 'eta': 0.42500000000000004, 'nthread': 6, 'colsample_bytree': 0.8500000000000001, 'max_depth': 4, 'alpha': 0.05, 'min_child_weight': 4.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.12160060642537115\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.5, 'n_estimators': 251.0, 'eval_metric': 'mlogloss', 'eta': 0.275, 'nthread': 6, 'colsample_bytree': 0.65, 'max_depth': 4, 'alpha': 0.55, 'min_child_weight': 3.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.11608735108442028\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 1288.0, 'eval_metric': 'mlogloss', 'eta': 0.275, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 11, 'alpha': 0.5, 'min_child_weight': 2.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.1282118430509975\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9, 'n_estimators': 1004.0, 'eval_metric': 'mlogloss', 'eta': 0.17500000000000002, 'nthread': 6, 'colsample_bytree': 0.7000000000000001, 'max_depth': 2, 'alpha': 0.45, 'min_child_weight': 3.0, 'gamma': 0.6000000000000001, 'silent': 1}\n",
      "\tScore 0.11318499450861857\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 1460.0, 'eval_metric': 'mlogloss', 'eta': 0.15000000000000002, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 6, 'alpha': 1.0, 'min_child_weight': 3.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.12189543559805725\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 136.0, 'eval_metric': 'mlogloss', 'eta': 0.17500000000000002, 'nthread': 6, 'colsample_bytree': 0.75, 'max_depth': 12, 'alpha': 0.45, 'min_child_weight': 3.0, 'gamma': 0.55, 'silent': 1}\n",
      "\tScore 0.11984820839351785\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 138.0, 'eval_metric': 'mlogloss', 'eta': 0.2, 'nthread': 6, 'colsample_bytree': 0.75, 'max_depth': 10, 'alpha': 0.8500000000000001, 'min_child_weight': 4.0, 'gamma': 0.6000000000000001, 'silent': 1}\n",
      "\tScore 0.113535163914369\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9, 'n_estimators': 247.0, 'eval_metric': 'mlogloss', 'eta': 0.35000000000000003, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 6, 'alpha': 0.25, 'min_child_weight': 1.0, 'gamma': 0.65, 'silent': 1}\n",
      "\tScore 0.12544615714747695\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.55, 'n_estimators': 893.0, 'eval_metric': 'mlogloss', 'eta': 0.45, 'nthread': 6, 'colsample_bytree': 0.55, 'max_depth': 8, 'alpha': 0.8500000000000001, 'min_child_weight': 5.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.1309816371937732\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 620.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 0.8500000000000001, 'max_depth': 3, 'alpha': 0.7000000000000001, 'min_child_weight': 6.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.11162974786713616\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.65, 'n_estimators': 504.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.8500000000000001, 'max_depth': 3, 'alpha': 0.7000000000000001, 'min_child_weight': 6.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.10970185038715802\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.65, 'n_estimators': 460.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.8500000000000001, 'max_depth': 3, 'alpha': 0.7000000000000001, 'min_child_weight': 1.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.10865881666184911\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.65, 'n_estimators': 455.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.8, 'max_depth': 1, 'alpha': 0.9500000000000001, 'min_child_weight': 1.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.13749901537543988\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.6000000000000001, 'n_estimators': 430.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 5, 'alpha': 0.65, 'min_child_weight': 1.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.11492697927467119\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 606.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 0.8, 'max_depth': 9, 'alpha': 0.9, 'min_child_weight': 1.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.11367091937790076\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.65, 'n_estimators': 372.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 3, 'alpha': 0.75, 'min_child_weight': 2.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.11051848927458868\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 567.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 3, 'alpha': 0.6000000000000001, 'min_child_weight': 1.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.10794100835433573\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 587.0, 'eval_metric': 'mlogloss', 'eta': 0.225, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 3, 'alpha': 0.4, 'min_child_weight': 1.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.11914012852427974\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.6000000000000001, 'n_estimators': 741.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 2, 'alpha': 0.6000000000000001, 'min_child_weight': 1.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.10906160095559736\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 692.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 9, 'alpha': 0.30000000000000004, 'min_child_weight': 2.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.12011643271971348\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.6000000000000001, 'n_estimators': 534.0, 'eval_metric': 'mlogloss', 'eta': 0.30000000000000004, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 1, 'alpha': 0.55, 'min_child_weight': 2.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.11657748410928884\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 779.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 5, 'alpha': 0.35000000000000003, 'min_child_weight': 1.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.11865031251668925\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.65, 'n_estimators': 658.0, 'eval_metric': 'mlogloss', 'eta': 0.5, 'nthread': 6, 'colsample_bytree': 0.8500000000000001, 'max_depth': 11, 'alpha': 0.6000000000000001, 'min_child_weight': 1.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.13404283203063472\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 1051.0, 'eval_metric': 'mlogloss', 'eta': 0.4, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 3, 'alpha': 0.75, 'min_child_weight': 2.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.12482824815360262\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.5, 'n_estimators': 822.0, 'eval_metric': 'mlogloss', 'eta': 0.15000000000000002, 'nthread': 6, 'colsample_bytree': 0.8, 'max_depth': 10, 'alpha': 0.5, 'min_child_weight': 2.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.13337014922931428\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8500000000000001, 'n_estimators': 506.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 0.5, 'max_depth': 3, 'alpha': 0.65, 'min_child_weight': 1.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.10929484594406025\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 332.0, 'eval_metric': 'mlogloss', 'eta': 0.25, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 3, 'alpha': 0.15000000000000002, 'min_child_weight': 5.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.1156259855265362\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 548.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 7, 'alpha': 0.4, 'min_child_weight': 2.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.12134933473882563\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 439.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 0.7000000000000001, 'max_depth': 8, 'alpha': 0.75, 'min_child_weight': 3.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.11024592436454302\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.6000000000000001, 'n_estimators': 969.0, 'eval_metric': 'mlogloss', 'eta': 0.325, 'nthread': 6, 'colsample_bytree': 0.6000000000000001, 'max_depth': 3, 'alpha': 1.0, 'min_child_weight': 1.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.12353562952687484\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.55, 'n_estimators': 201.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 0.8500000000000001, 'max_depth': 5, 'alpha': 0.6000000000000001, 'min_child_weight': 2.0, 'gamma': 0.65, 'silent': 1}\n",
      "\tScore 0.1091357168754955\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8500000000000001, 'n_estimators': 702.0, 'eval_metric': 'mlogloss', 'eta': 0.2, 'nthread': 6, 'colsample_bytree': 0.8, 'max_depth': 9, 'alpha': 0.8, 'min_child_weight': 1.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.11831921098540199\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 295.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.7000000000000001, 'max_depth': 2, 'alpha': 0.7000000000000001, 'min_child_weight': 4.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.12577897599672375\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.65, 'n_estimators': 170.0, 'eval_metric': 'mlogloss', 'eta': 0.4, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 11, 'alpha': 0.55, 'min_child_weight': 3.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.1272449779418499\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 932.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 4, 'alpha': 0.9, 'min_child_weight': 2.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.11624516481065932\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.5, 'n_estimators': 1101.0, 'eval_metric': 'mlogloss', 'eta': 0.15000000000000002, 'nthread': 6, 'colsample_bytree': 0.8500000000000001, 'max_depth': 12, 'alpha': 0.45, 'min_child_weight': 5.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.13226944912698702\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.55, 'n_estimators': 1228.0, 'eval_metric': 'mlogloss', 'eta': 0.225, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 7, 'alpha': 0.05, 'min_child_weight': 3.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.14958781385311118\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 744.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 6, 'alpha': 0.15000000000000002, 'min_child_weight': 1.0, 'gamma': 0.55, 'silent': 1}\n",
      "\tScore 0.1102575619852278\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 852.0, 'eval_metric': 'mlogloss', 'eta': 0.2, 'nthread': 6, 'colsample_bytree': 0.75, 'max_depth': 10, 'alpha': 0.35000000000000003, 'min_child_weight': 4.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.12638389320017843\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8500000000000001, 'n_estimators': 1324.0, 'eval_metric': 'mlogloss', 'eta': 0.25, 'nthread': 6, 'colsample_bytree': 0.65, 'max_depth': 1, 'alpha': 0.5, 'min_child_weight': 2.0, 'gamma': 0.65, 'silent': 1}\n",
      "\tScore 0.11720668354217469\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 352.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 3, 'alpha': 0.9, 'min_child_weight': 3.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.10842535425027619\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9, 'n_estimators': 265.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 8, 'alpha': 0.9, 'min_child_weight': 4.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.11042342461581912\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 659.0, 'eval_metric': 'mlogloss', 'eta': 0.17500000000000002, 'nthread': 6, 'colsample_bytree': 0.6000000000000001, 'max_depth': 4, 'alpha': 0.9500000000000001, 'min_child_weight': 5.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.11273233271566949\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 347.0, 'eval_metric': 'mlogloss', 'eta': 0.325, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 12, 'alpha': 0.8, 'min_child_weight': 6.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.12244083872127148\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 118.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 0.5, 'max_depth': 3, 'alpha': 1.0, 'min_child_weight': 3.0, 'gamma': 0.5, 'silent': 1}\n",
      "\tScore 0.11247739882536432\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8500000000000001, 'n_estimators': 398.0, 'eval_metric': 'mlogloss', 'eta': 0.15000000000000002, 'nthread': 6, 'colsample_bytree': 0.8, 'max_depth': 6, 'alpha': 0.8500000000000001, 'min_child_weight': 4.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.1136753546551998\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 290.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 2, 'alpha': 0.25, 'min_child_weight': 3.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.10858729470478382\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 1417.0, 'eval_metric': 'mlogloss', 'eta': 0.375, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 3, 'alpha': 0.65, 'min_child_weight': 5.0, 'gamma': 0.55, 'silent': 1}\n",
      "\tScore 0.12978141771289217\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 207.0, 'eval_metric': 'mlogloss', 'eta': 0.47500000000000003, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 7, 'alpha': 0.0, 'min_child_weight': 6.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.1359226296498772\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9, 'n_estimators': 586.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 0.75, 'max_depth': 11, 'alpha': 0.8, 'min_child_weight': 4.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.11286007022635576\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 481.0, 'eval_metric': 'mlogloss', 'eta': 0.275, 'nthread': 6, 'colsample_bytree': 0.7000000000000001, 'max_depth': 10, 'alpha': 0.2, 'min_child_weight': 3.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.12687226079861888\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8500000000000001, 'n_estimators': 398.0, 'eval_metric': 'mlogloss', 'eta': 0.2, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 1, 'alpha': 0.4, 'min_child_weight': 4.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.11556076039174609\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.65, 'n_estimators': 790.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 0.6000000000000001, 'max_depth': 3, 'alpha': 0.9500000000000001, 'min_child_weight': 3.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.10948109227190157\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.6000000000000001, 'n_estimators': 107.0, 'eval_metric': 'mlogloss', 'eta': 0.30000000000000004, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 9, 'alpha': 0.9500000000000001, 'min_child_weight': 5.0, 'gamma': 0.6000000000000001, 'silent': 1}\n",
      "\tScore 0.1192648973389003\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 299.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 2, 'alpha': 0.25, 'min_child_weight': 3.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.10862502196072546\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 549.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 2, 'alpha': 0.1, 'min_child_weight': 3.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.11217905334366987\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 169.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 0.8500000000000001, 'max_depth': 2, 'alpha': 0.30000000000000004, 'min_child_weight': 3.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.10959282278231026\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 358.0, 'eval_metric': 'mlogloss', 'eta': 0.17500000000000002, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 2, 'alpha': 0.30000000000000004, 'min_child_weight': 2.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.10956421764831856\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 637.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 5, 'alpha': 0.1, 'min_child_weight': 4.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.11630075810373652\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 288.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 2, 'alpha': 0.45, 'min_child_weight': 2.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.11141034575379834\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 237.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 3, 'alpha': 0.1, 'min_child_weight': 3.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.10781768453277389\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.65, 'n_estimators': 234.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 3, 'alpha': 0.0, 'min_child_weight': 3.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.10791124942577436\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.65, 'n_estimators': 247.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 3, 'alpha': 0.0, 'min_child_weight': 4.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.11472448762652049\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.6000000000000001, 'n_estimators': 153.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 0.8, 'max_depth': 3, 'alpha': 0.2, 'min_child_weight': 2.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.10920107045391154\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.65, 'n_estimators': 422.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 3, 'alpha': 0.0, 'min_child_weight': 3.0, 'gamma': 0.65, 'silent': 1}\n",
      "\tScore 0.10866339910603023\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.55, 'n_estimators': 514.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 0.8500000000000001, 'max_depth': 8, 'alpha': 0.05, 'min_child_weight': 2.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.13166621249332194\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 197.0, 'eval_metric': 'mlogloss', 'eta': 0.15000000000000002, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 3, 'alpha': 0.1, 'min_child_weight': 5.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.10987531042619728\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.6000000000000001, 'n_estimators': 571.0, 'eval_metric': 'mlogloss', 'eta': 0.17500000000000002, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 12, 'alpha': 0.15000000000000002, 'min_child_weight': 2.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.14025459720756756\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 103.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.8500000000000001, 'max_depth': 3, 'alpha': 0.6000000000000001, 'min_child_weight': 4.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.1896174417607069\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 464.0, 'eval_metric': 'mlogloss', 'eta': 0.2, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 6, 'alpha': 0.55, 'min_child_weight': 1.0, 'gamma': 0.65, 'silent': 1}\n",
      "\tScore 0.12408581095795922\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.65, 'n_estimators': 932.0, 'eval_metric': 'mlogloss', 'eta': 0.225, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 4, 'alpha': 0.5, 'min_child_weight': 3.0, 'gamma': 0.6000000000000001, 'silent': 1}\n",
      "\tScore 0.13326576869378517\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8500000000000001, 'n_estimators': 668.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 11, 'alpha': 0.2, 'min_child_weight': 4.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.12461960634582381\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.55, 'n_estimators': 746.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 0.8, 'max_depth': 3, 'alpha': 0.4, 'min_child_weight': 6.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.11280218766657679\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9, 'n_estimators': 318.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 0.8500000000000001, 'max_depth': 5, 'alpha': 0.05, 'min_child_weight': 2.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.10849773695274251\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 832.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 9, 'alpha': 0.35000000000000003, 'min_child_weight': 1.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.1283104672532392\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.6000000000000001, 'n_estimators': 1059.0, 'eval_metric': 'mlogloss', 'eta': 0.15000000000000002, 'nthread': 6, 'colsample_bytree': 0.75, 'max_depth': 7, 'alpha': 0.75, 'min_child_weight': 3.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.12833401787519966\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.65, 'n_estimators': 216.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 10, 'alpha': 0.7000000000000001, 'min_child_weight': 2.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.11264673434615347\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 1170.0, 'eval_metric': 'mlogloss', 'eta': 0.45, 'nthread': 6, 'colsample_bytree': 0.55, 'max_depth': 1, 'alpha': 0.1, 'min_child_weight': 1.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.11823834267413602\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 378.0, 'eval_metric': 'mlogloss', 'eta': 0.25, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 3, 'alpha': 0.65, 'min_child_weight': 4.0, 'gamma': 0.55, 'silent': 1}\n",
      "\tScore 0.11559702929636241\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.5, 'n_estimators': 618.0, 'eval_metric': 'mlogloss', 'eta': 0.225, 'nthread': 6, 'colsample_bytree': 0.8, 'max_depth': 8, 'alpha': 0.55, 'min_child_weight': 3.0, 'gamma': 0.65, 'silent': 1}\n",
      "\tScore 0.13765562750076596\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.65, 'n_estimators': 420.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 3, 'alpha': 0.0, 'min_child_weight': 1.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.1111194014817436\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 257.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 4, 'alpha': 0.05, 'min_child_weight': 3.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.10874278544058037\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 502.0, 'eval_metric': 'mlogloss', 'eta': 0.17500000000000002, 'nthread': 6, 'colsample_bytree': 0.8500000000000001, 'max_depth': 12, 'alpha': 0.30000000000000004, 'min_child_weight': 2.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.12963985643576809\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8500000000000001, 'n_estimators': 1002.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 6, 'alpha': 0.15000000000000002, 'min_child_weight': 5.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.1167383568773058\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.55, 'n_estimators': 183.0, 'eval_metric': 'mlogloss', 'eta': 0.30000000000000004, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 3, 'alpha': 0.45, 'min_child_weight': 3.0, 'gamma': 0.6000000000000001, 'silent': 1}\n",
      "\tScore 0.1140124681017201\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 144.0, 'eval_metric': 'mlogloss', 'eta': 0.15000000000000002, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 3, 'alpha': 0.6000000000000001, 'min_child_weight': 6.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.10911138598678807\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.6000000000000001, 'n_estimators': 701.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.8500000000000001, 'max_depth': 7, 'alpha': 0.2, 'min_child_weight': 4.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.11270135439222481\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 879.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 0.65, 'max_depth': 11, 'alpha': 0.35000000000000003, 'min_child_weight': 1.0, 'gamma': 0.5, 'silent': 1}\n",
      "\tScore 0.12908634045583486\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 475.0, 'eval_metric': 'mlogloss', 'eta': 0.375, 'nthread': 6, 'colsample_bytree': 0.7000000000000001, 'max_depth': 9, 'alpha': 0.65, 'min_child_weight': 2.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.1272519726368829\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 316.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 5, 'alpha': 0.25, 'min_child_weight': 4.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.11423789184155324\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.65, 'n_estimators': 533.0, 'eval_metric': 'mlogloss', 'eta': 0.2, 'nthread': 6, 'colsample_bytree': 0.75, 'max_depth': 10, 'alpha': 0.7000000000000001, 'min_child_weight': 3.0, 'gamma': 0.65, 'silent': 1}\n",
      "\tScore 0.12935910397357733\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8500000000000001, 'n_estimators': 730.0, 'eval_metric': 'mlogloss', 'eta': 0.17500000000000002, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 1, 'alpha': 0.5, 'min_child_weight': 2.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.11553097606170787\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9, 'n_estimators': 231.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 3, 'alpha': 0.75, 'min_child_weight': 5.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.10983969849393733\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 775.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 0.8, 'max_depth': 8, 'alpha': 0.05, 'min_child_weight': 3.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.13075556372237845\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 909.0, 'eval_metric': 'mlogloss', 'eta': 0.25, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 3, 'alpha': 0.4, 'min_child_weight': 4.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.10970138418118726\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 439.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 12, 'alpha': 0.1, 'min_child_weight': 1.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.12082488009900423\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 131.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 4, 'alpha': 0.55, 'min_child_weight': 2.0, 'gamma': 0.6000000000000001, 'silent': 1}\n",
      "\tScore 0.14604592820024728\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.65, 'n_estimators': 582.0, 'eval_metric': 'mlogloss', 'eta': 0.5, 'nthread': 6, 'colsample_bytree': 0.8500000000000001, 'max_depth': 6, 'alpha': 0.0, 'min_child_weight': 2.0, 'gamma': 0.65, 'silent': 1}\n",
      "\tScore 0.160563182474918\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 399.0, 'eval_metric': 'mlogloss', 'eta': 0.325, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 3, 'alpha': 0.45, 'min_child_weight': 4.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.11622880029934127\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.6000000000000001, 'n_estimators': 281.0, 'eval_metric': 'mlogloss', 'eta': 0.275, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 3, 'alpha': 0.8500000000000001, 'min_child_weight': 3.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.11331364391624929\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 337.0, 'eval_metric': 'mlogloss', 'eta': 0.15000000000000002, 'nthread': 6, 'colsample_bytree': 0.7000000000000001, 'max_depth': 11, 'alpha': 0.25, 'min_child_weight': 5.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.1256256456598741\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 104.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 7, 'alpha': 0.30000000000000004, 'min_child_weight': 3.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.1096152011115051\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 679.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 0.65, 'max_depth': 9, 'alpha': 0.6000000000000001, 'min_child_weight': 1.0, 'gamma': 0.55, 'silent': 1}\n",
      "\tScore 0.12139358524052622\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.65, 'n_estimators': 624.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 0.8500000000000001, 'max_depth': 5, 'alpha': 0.15000000000000002, 'min_child_weight': 2.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.1135493326377665\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.55, 'n_estimators': 1289.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 10, 'alpha': 0.1, 'min_child_weight': 3.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.13000420035852794\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.6000000000000001, 'n_estimators': 563.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.8, 'max_depth': 3, 'alpha': 0.5, 'min_child_weight': 4.0, 'gamma': 0.6000000000000001, 'silent': 1}\n",
      "\tScore 0.10882421134397188\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8500000000000001, 'n_estimators': 1463.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 0.75, 'max_depth': 1, 'alpha': 0.35000000000000003, 'min_child_weight': 2.0, 'gamma': 0.65, 'silent': 1}\n",
      "\tScore 0.11645127719233371\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 823.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 8, 'alpha': 0.45, 'min_child_weight': 1.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.12484984639935415\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 232.0, 'eval_metric': 'mlogloss', 'eta': 0.42500000000000004, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 3, 'alpha': 0.2, 'min_child_weight': 4.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.11628688068146902\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9, 'n_estimators': 362.0, 'eval_metric': 'mlogloss', 'eta': 0.225, 'nthread': 6, 'colsample_bytree': 0.55, 'max_depth': 12, 'alpha': 0.65, 'min_child_weight': 3.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.11737543941238932\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.5, 'n_estimators': 507.0, 'eval_metric': 'mlogloss', 'eta': 0.17500000000000002, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 4, 'alpha': 0.7000000000000001, 'min_child_weight': 6.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.11725191105301867\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 1374.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 3, 'alpha': 0.8, 'min_child_weight': 1.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.11482931880737472\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8500000000000001, 'n_estimators': 160.0, 'eval_metric': 'mlogloss', 'eta': 0.15000000000000002, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 6, 'alpha': 0.05, 'min_child_weight': 3.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.11386656187575928\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 604.0, 'eval_metric': 'mlogloss', 'eta': 0.375, 'nthread': 6, 'colsample_bytree': 0.8500000000000001, 'max_depth': 3, 'alpha': 0.6000000000000001, 'min_child_weight': 5.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.12009504795663814\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.65, 'n_estimators': 648.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 11, 'alpha': 0.8500000000000001, 'min_child_weight': 2.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.11325574526978462\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.6000000000000001, 'n_estimators': 1165.0, 'eval_metric': 'mlogloss', 'eta': 0.2, 'nthread': 6, 'colsample_bytree': 0.6000000000000001, 'max_depth': 7, 'alpha': 0.75, 'min_child_weight': 4.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.12771308171178483\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 982.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 9, 'alpha': 0.4, 'min_child_weight': 3.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.12249246020691294\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 266.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 0.8500000000000001, 'max_depth': 5, 'alpha': 0.15000000000000002, 'min_child_weight': 2.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.11541996440778851\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 192.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 10, 'alpha': 0.55, 'min_child_weight': 1.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.11193805604707488\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.65, 'n_estimators': 457.0, 'eval_metric': 'mlogloss', 'eta': 0.35000000000000003, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 3, 'alpha': 0.0, 'min_child_weight': 5.0, 'gamma': 0.5, 'silent': 1}\n",
      "\tScore 0.12569238915902903\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9, 'n_estimators': 1035.0, 'eval_metric': 'mlogloss', 'eta': 0.47500000000000003, 'nthread': 6, 'colsample_bytree': 0.8, 'max_depth': 1, 'alpha': 0.30000000000000004, 'min_child_weight': 3.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.11691100072622665\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 407.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 2, 'alpha': 0.8, 'min_child_weight': 2.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.10913989451940016\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 486.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 3, 'alpha': 0.5, 'min_child_weight': 4.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.10875333419413101\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8500000000000001, 'n_estimators': 334.0, 'eval_metric': 'mlogloss', 'eta': 0.15000000000000002, 'nthread': 6, 'colsample_bytree': 0.75, 'max_depth': 8, 'alpha': 0.25, 'min_child_weight': 3.0, 'gamma': 0.55, 'silent': 1}\n",
      "\tScore 0.12412562236310362\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.6000000000000001, 'n_estimators': 855.0, 'eval_metric': 'mlogloss', 'eta': 0.275, 'nthread': 6, 'colsample_bytree': 0.8500000000000001, 'max_depth': 12, 'alpha': 0.45, 'min_child_weight': 4.0, 'gamma': 0.65, 'silent': 1}\n",
      "\tScore 0.1447979026687835\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.55, 'n_estimators': 375.0, 'eval_metric': 'mlogloss', 'eta': 0.225, 'nthread': 6, 'colsample_bytree': 0.5, 'max_depth': 4, 'alpha': 0.2, 'min_child_weight': 6.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.11668947465485603\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 541.0, 'eval_metric': 'mlogloss', 'eta': 0.30000000000000004, 'nthread': 6, 'colsample_bytree': 0.8, 'max_depth': 3, 'alpha': 0.15000000000000002, 'min_child_weight': 1.0, 'gamma': 0.6000000000000001, 'silent': 1}\n",
      "\tScore 0.12587954555333303\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.65, 'n_estimators': 770.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 6, 'alpha': 0.05, 'min_child_weight': 5.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.11716480786198429\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.5, 'n_estimators': 724.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 3, 'alpha': 0.9, 'min_child_weight': 2.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.1127191347350822\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 313.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 7, 'alpha': 0.55, 'min_child_weight': 3.0, 'gamma': 0.65, 'silent': 1}\n",
      "\tScore 0.11456216222138442\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 1100.0, 'eval_metric': 'mlogloss', 'eta': 0.25, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 10, 'alpha': 0.35000000000000003, 'min_child_weight': 2.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.13691172458292294\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 119.0, 'eval_metric': 'mlogloss', 'eta': 0.17500000000000002, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 11, 'alpha': 0.7000000000000001, 'min_child_weight': 1.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.11572015601180591\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 207.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 0.8, 'max_depth': 9, 'alpha': 0.1, 'min_child_weight': 3.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.11736257152837488\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.55, 'n_estimators': 800.0, 'eval_metric': 'mlogloss', 'eta': 0.2, 'nthread': 6, 'colsample_bytree': 0.7000000000000001, 'max_depth': 5, 'alpha': 0.0, 'min_child_weight': 4.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.13553184185420133\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 353.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 3, 'alpha': 0.75, 'min_child_weight': 3.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.10820306253882882\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 449.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 3, 'alpha': 0.65, 'min_child_weight': 3.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.10859289286721148\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 263.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 3, 'alpha': 0.75, 'min_child_weight': 3.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.10844743673886618\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 425.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 3, 'alpha': 0.8, 'min_child_weight': 3.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.10826990602283319\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 384.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 3, 'alpha': 0.8500000000000001, 'min_child_weight': 3.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.10923295930519199\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 291.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 3, 'alpha': 0.7000000000000001, 'min_child_weight': 3.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.11255392456134158\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 167.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 3, 'alpha': 0.65, 'min_child_weight': 4.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.10805249727036154\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.65, 'n_estimators': 159.0, 'eval_metric': 'mlogloss', 'eta': 0.15000000000000002, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 3, 'alpha': 0.6000000000000001, 'min_child_weight': 4.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.108630185205979\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.65, 'n_estimators': 233.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 1, 'alpha': 0.65, 'min_child_weight': 4.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.11743597568449153\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 173.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 2, 'alpha': 0.55, 'min_child_weight': 4.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.11855553366674955\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.65, 'n_estimators': 218.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 3, 'alpha': 0.5, 'min_child_weight': 5.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.10944940372264288\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 105.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 8, 'alpha': 0.6000000000000001, 'min_child_weight': 4.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.10997151229252353\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.6000000000000001, 'n_estimators': 128.0, 'eval_metric': 'mlogloss', 'eta': 0.17500000000000002, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 3, 'alpha': 0.65, 'min_child_weight': 5.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.11036095505829592\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 310.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 12, 'alpha': 0.4, 'min_child_weight': 5.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.11372242456061442\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.6000000000000001, 'n_estimators': 257.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 6, 'alpha': 0.7000000000000001, 'min_child_weight': 4.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.11085922140073814\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 518.0, 'eval_metric': 'mlogloss', 'eta': 0.15000000000000002, 'nthread': 6, 'colsample_bytree': 0.8500000000000001, 'max_depth': 4, 'alpha': 0.6000000000000001, 'min_child_weight': 4.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.11494626820907584\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.65, 'n_estimators': 186.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 3, 'alpha': 0.65, 'min_child_weight': 4.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.12131302197856692\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 136.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 11, 'alpha': 0.45, 'min_child_weight': 6.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.11050574667340396\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 101.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 7, 'alpha': 0.55, 'min_child_weight': 4.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.10917227797213423\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 470.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 3, 'alpha': 0.5, 'min_child_weight': 4.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.11141257332304244\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.65, 'n_estimators': 952.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 9, 'alpha': 0.9, 'min_child_weight': 5.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.12138624821732834\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 599.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 5, 'alpha': 0.7000000000000001, 'min_child_weight': 5.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.11552280215816485\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8500000000000001, 'n_estimators': 284.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 10, 'alpha': 0.75, 'min_child_weight': 3.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.1091877307444846\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.65, 'n_estimators': 699.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 0.8500000000000001, 'max_depth': 1, 'alpha': 0.8, 'min_child_weight': 4.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.1159957585571383\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 558.0, 'eval_metric': 'mlogloss', 'eta': 0.17500000000000002, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 3, 'alpha': 0.6000000000000001, 'min_child_weight': 2.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.11421781126118664\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.6000000000000001, 'n_estimators': 335.0, 'eval_metric': 'mlogloss', 'eta': 0.2, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 2, 'alpha': 0.4, 'min_child_weight': 4.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.11108843307197006\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 413.0, 'eval_metric': 'mlogloss', 'eta': 0.15000000000000002, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 3, 'alpha': 0.5, 'min_child_weight': 3.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.11277122827220654\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 651.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 8, 'alpha': 0.6000000000000001, 'min_child_weight': 6.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.11464289560533515\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 1227.0, 'eval_metric': 'mlogloss', 'eta': 0.225, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 4, 'alpha': 0.55, 'min_child_weight': 2.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.12950779803321605\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 905.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.55, 'max_depth': 12, 'alpha': 0.35000000000000003, 'min_child_weight': 5.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.11385770986525359\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8500000000000001, 'n_estimators': 487.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 0.6000000000000001, 'max_depth': 3, 'alpha': 0.9500000000000001, 'min_child_weight': 4.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.10998204195205284\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 249.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 3, 'alpha': 0.05, 'min_child_weight': 3.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.10915634000055767\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 388.0, 'eval_metric': 'mlogloss', 'eta': 0.325, 'nthread': 6, 'colsample_bytree': 0.8500000000000001, 'max_depth': 6, 'alpha': 0.45, 'min_child_weight': 2.0, 'gamma': 0.65, 'silent': 1}\n",
      "\tScore 0.1324277792794701\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.6000000000000001, 'n_estimators': 211.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 11, 'alpha': 0.65, 'min_child_weight': 1.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.11399066050259421\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.65, 'n_estimators': 167.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 9, 'alpha': 0.7000000000000001, 'min_child_weight': 3.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.12119860245488179\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 349.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 7, 'alpha': 0.1, 'min_child_weight': 4.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.1119268810090077\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.55, 'n_estimators': 434.0, 'eval_metric': 'mlogloss', 'eta': 0.15000000000000002, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 3, 'alpha': 1.0, 'min_child_weight': 3.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.11162237276911391\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 142.0, 'eval_metric': 'mlogloss', 'eta': 0.4, 'nthread': 6, 'colsample_bytree': 0.75, 'max_depth': 5, 'alpha': 0.55, 'min_child_weight': 2.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.11876927525187977\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 1490.0, 'eval_metric': 'mlogloss', 'eta': 0.17500000000000002, 'nthread': 6, 'colsample_bytree': 0.8500000000000001, 'max_depth': 10, 'alpha': 0.15000000000000002, 'min_child_weight': 4.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.13245946937799616\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.6000000000000001, 'n_estimators': 756.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 0.65, 'max_depth': 1, 'alpha': 0.2, 'min_child_weight': 5.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.11618939541451959\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.65, 'n_estimators': 576.0, 'eval_metric': 'mlogloss', 'eta': 0.42500000000000004, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 3, 'alpha': 0.0, 'min_child_weight': 1.0, 'gamma': 0.65, 'silent': 1}\n",
      "\tScore 0.13906948855091233\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.5, 'n_estimators': 286.0, 'eval_metric': 'mlogloss', 'eta': 0.25, 'nthread': 6, 'colsample_bytree': 0.8, 'max_depth': 2, 'alpha': 0.8, 'min_child_weight': 3.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.11000136367284795\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8500000000000001, 'n_estimators': 529.0, 'eval_metric': 'mlogloss', 'eta': 0.2, 'nthread': 6, 'colsample_bytree': 0.7000000000000001, 'max_depth': 3, 'alpha': 0.8500000000000001, 'min_child_weight': 4.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.11310662622415281\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 370.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 8, 'alpha': 0.30000000000000004, 'min_child_weight': 3.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.11962013557337578\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 800.0, 'eval_metric': 'mlogloss', 'eta': 0.30000000000000004, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 12, 'alpha': 0.7000000000000001, 'min_child_weight': 2.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.12765635429039313\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.65, 'n_estimators': 102.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 3, 'alpha': 0.25, 'min_child_weight': 6.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.11134891854754299\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.55, 'n_estimators': 320.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 4, 'alpha': 0.75, 'min_child_weight': 3.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.10835399988118016\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 233.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.8500000000000001, 'max_depth': 6, 'alpha': 0.05, 'min_child_weight': 5.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.11044588113821703\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9, 'n_estimators': 679.0, 'eval_metric': 'mlogloss', 'eta': 0.15000000000000002, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 3, 'alpha': 0.6000000000000001, 'min_child_weight': 1.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.1122294509448559\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 185.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 11, 'alpha': 0.4, 'min_child_weight': 4.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.11575791687593553\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 452.0, 'eval_metric': 'mlogloss', 'eta': 0.17500000000000002, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 7, 'alpha': 0.5, 'min_child_weight': 4.0, 'gamma': 0.65, 'silent': 1}\n",
      "\tScore 0.12660098671623754\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.65, 'n_estimators': 617.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 3, 'alpha': 0.65, 'min_child_weight': 2.0, 'gamma': 0.6000000000000001, 'silent': 1}\n",
      "\tScore 0.11496463162884192\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 504.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.8, 'max_depth': 9, 'alpha': 0.75, 'min_child_weight': 3.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.110506210798673\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 392.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 0.8500000000000001, 'max_depth': 10, 'alpha': 0.45, 'min_child_weight': 5.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.11630559580862905\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.6000000000000001, 'n_estimators': 213.0, 'eval_metric': 'mlogloss', 'eta': 0.35000000000000003, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 5, 'alpha': 0.8500000000000001, 'min_child_weight': 3.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.12114747238591646\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 860.0, 'eval_metric': 'mlogloss', 'eta': 0.15000000000000002, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 3, 'alpha': 0.55, 'min_child_weight': 4.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.11682812991616859\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 278.0, 'eval_metric': 'mlogloss', 'eta': 0.275, 'nthread': 6, 'colsample_bytree': 0.75, 'max_depth': 2, 'alpha': 0.1, 'min_child_weight': 1.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.111408700594344\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.65, 'n_estimators': 1028.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 1, 'alpha': 0.35000000000000003, 'min_child_weight': 2.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.11524379603662278\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8500000000000001, 'n_estimators': 129.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 3, 'alpha': 0.0, 'min_child_weight': 3.0, 'gamma': 0.6000000000000001, 'silent': 1}\n",
      "\tScore 0.10909118395156789\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.6000000000000001, 'n_estimators': 1082.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 8, 'alpha': 0.15000000000000002, 'min_child_weight': 4.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.1370891325913915\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 1430.0, 'eval_metric': 'mlogloss', 'eta': 0.2, 'nthread': 6, 'colsample_bytree': 0.65, 'max_depth': 3, 'alpha': 0.65, 'min_child_weight': 4.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.11890168036093766\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 310.0, 'eval_metric': 'mlogloss', 'eta': 0.225, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 12, 'alpha': 0.5, 'min_child_weight': 2.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.12220627956939645\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 246.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 4, 'alpha': 0.6000000000000001, 'min_child_weight': 5.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.10829246874633731\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 549.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 6, 'alpha': 0.4, 'min_child_weight': 3.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.1145944670085775\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.65, 'n_estimators': 715.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.5, 'max_depth': 3, 'alpha': 0.25, 'min_child_weight': 6.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.11163858424682223\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 102.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 11, 'alpha': 1.0, 'min_child_weight': 4.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.11035278527895796\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 157.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 0.8500000000000001, 'max_depth': 3, 'alpha': 0.8, 'min_child_weight': 2.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.10868699003653912\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.55, 'n_estimators': 636.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 9, 'alpha': 0.9, 'min_child_weight': 1.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.1141459245611342\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 426.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 7, 'alpha': 0.75, 'min_child_weight': 3.0, 'gamma': 0.65, 'silent': 1}\n",
      "\tScore 0.12088657225143849\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9, 'n_estimators': 345.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 5, 'alpha': 0.7000000000000001, 'min_child_weight': 3.0, 'gamma': 0.5, 'silent': 1}\n",
      "\tScore 0.11374072461742947\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 1142.0, 'eval_metric': 'mlogloss', 'eta': 0.17500000000000002, 'nthread': 6, 'colsample_bytree': 0.8, 'max_depth': 10, 'alpha': 0.45, 'min_child_weight': 2.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.12817804559699988\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8500000000000001, 'n_estimators': 181.0, 'eval_metric': 'mlogloss', 'eta': 0.15000000000000002, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 3, 'alpha': 0.55, 'min_child_weight': 5.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.10919364655395532\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.65, 'n_estimators': 473.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 0.8500000000000001, 'max_depth': 2, 'alpha': 0.2, 'min_child_weight': 4.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.1093419525178567\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.6000000000000001, 'n_estimators': 590.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 3, 'alpha': 0.30000000000000004, 'min_child_weight': 1.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.10889740603884708\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1272.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 3, 'alpha': 0.1, 'min_child_weight': 3.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.10797352106492757\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 994.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.8, 'max_depth': 1, 'alpha': 0.1, 'min_child_weight': 2.0, 'gamma': 0.65, 'silent': 1}\n",
      "\tScore 0.12005697777297712\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 1251.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 12, 'alpha': 0.05, 'min_child_weight': 2.0, 'gamma': 0.55, 'silent': 1}\n",
      "\tScore 0.12284190548793811\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.5, 'n_estimators': 1382.0, 'eval_metric': 'mlogloss', 'eta': 0.375, 'nthread': 6, 'colsample_bytree': 0.8500000000000001, 'max_depth': 8, 'alpha': 0.0, 'min_child_weight': 3.0, 'gamma': 0.6000000000000001, 'silent': 1}\n",
      "\tScore 0.17429273318149768\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9, 'n_estimators': 1350.0, 'eval_metric': 'mlogloss', 'eta': 0.45, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 4, 'alpha': 0.2, 'min_child_weight': 3.0, 'gamma': 0.6000000000000001, 'silent': 1}\n",
      "\tScore 0.13652648506993728\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 1312.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 3, 'alpha': 0.1, 'min_child_weight': 3.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.11202813036534069\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.55, 'n_estimators': 925.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 6, 'alpha': 0.05, 'min_child_weight': 2.0, 'gamma': 0.55, 'silent': 1}\n",
      "\tScore 0.11506321026372067\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9, 'n_estimators': 831.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 0.75, 'max_depth': 3, 'alpha': 0.15000000000000002, 'min_child_weight': 3.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.11178932239495726\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9, 'n_estimators': 1179.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 11, 'alpha': 0.25, 'min_child_weight': 2.0, 'gamma': 0.65, 'silent': 1}\n",
      "\tScore 0.11945639035134704\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1438.0, 'eval_metric': 'mlogloss', 'eta': 0.5, 'nthread': 6, 'colsample_bytree': 0.8500000000000001, 'max_depth': 7, 'alpha': 0.0, 'min_child_weight': 3.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.12120358750174753\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.55, 'n_estimators': 1191.0, 'eval_metric': 'mlogloss', 'eta': 0.47500000000000003, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 9, 'alpha': 0.30000000000000004, 'min_child_weight': 2.0, 'gamma': 0.65, 'silent': 1}\n",
      "\tScore 0.16277048882872078\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 878.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 0.7000000000000001, 'max_depth': 3, 'alpha': 0.1, 'min_child_weight': 3.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.10937468588555535\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.5, 'n_estimators': 1108.0, 'eval_metric': 'mlogloss', 'eta': 0.325, 'nthread': 6, 'colsample_bytree': 0.8, 'max_depth': 10, 'alpha': 0.15000000000000002, 'min_child_weight': 1.0, 'gamma': 0.65, 'silent': 1}\n",
      "\tScore 0.1578768167595659\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1259.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 0.8500000000000001, 'max_depth': 5, 'alpha': 0.05, 'min_child_weight': 3.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.10829218598462596\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 1401.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 3, 'alpha': 0.0, 'min_child_weight': 2.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.10929608407436711\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1059.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 1, 'alpha': 0.2, 'min_child_weight': 3.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.11588446867412669\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8500000000000001, 'n_estimators': 959.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 2, 'alpha': 0.25, 'min_child_weight': 2.0, 'gamma': 0.65, 'silent': 1}\n",
      "\tScore 0.11162981855401251\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9, 'n_estimators': 736.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 8, 'alpha': 0.15000000000000002, 'min_child_weight': 1.0, 'gamma': 0.6000000000000001, 'silent': 1}\n",
      "\tScore 0.12482370079613155\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.5, 'n_estimators': 1330.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 3, 'alpha': 0.05, 'min_child_weight': 3.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.11428905894880113\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8500000000000001, 'n_estimators': 1197.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 12, 'alpha': 0.15000000000000002, 'min_child_weight': 2.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.12173084505614588\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 1488.0, 'eval_metric': 'mlogloss', 'eta': 0.25, 'nthread': 6, 'colsample_bytree': 0.8500000000000001, 'max_depth': 4, 'alpha': 0.1, 'min_child_weight': 3.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.13386486756822774\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 1141.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 3, 'alpha': 0.0, 'min_child_weight': 2.0, 'gamma': 0.65, 'silent': 1}\n",
      "\tScore 0.1175762420710891\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 525.0, 'eval_metric': 'mlogloss', 'eta': 0.30000000000000004, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 6, 'alpha': 0.35000000000000003, 'min_child_weight': 3.0, 'gamma': 0.6000000000000001, 'silent': 1}\n",
      "\tScore 0.11186900366309753\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.5, 'n_estimators': 1018.0, 'eval_metric': 'mlogloss', 'eta': 0.15000000000000002, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 3, 'alpha': 0.2, 'min_child_weight': 3.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.12328640620654066\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.6000000000000001, 'n_estimators': 677.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 11, 'alpha': 0.05, 'min_child_weight': 1.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.13433710063145246\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8500000000000001, 'n_estimators': 1260.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 0.55, 'max_depth': 9, 'alpha': 0.30000000000000004, 'min_child_weight': 2.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.1182791009108222\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.6000000000000001, 'n_estimators': 803.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.75, 'max_depth': 7, 'alpha': 0.1, 'min_child_weight': 3.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.11359831386628946\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 654.0, 'eval_metric': 'mlogloss', 'eta': 0.2, 'nthread': 6, 'colsample_bytree': 0.8500000000000001, 'max_depth': 3, 'alpha': 0.25, 'min_child_weight': 1.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.10804214872685894\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.55, 'n_estimators': 899.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 0.8, 'max_depth': 5, 'alpha': 0.0, 'min_child_weight': 3.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.12323469966630045\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9, 'n_estimators': 565.0, 'eval_metric': 'mlogloss', 'eta': 0.42500000000000004, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 10, 'alpha': 0.1, 'min_child_weight': 2.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.1361192122202497\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 409.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 1, 'alpha': 0.2, 'min_child_weight': 3.0, 'gamma': 0.55, 'silent': 1}\n",
      "\tScore 0.11659984738211593\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8500000000000001, 'n_estimators': 952.0, 'eval_metric': 'mlogloss', 'eta': 0.225, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 3, 'alpha': 0.05, 'min_child_weight': 1.0, 'gamma': 0.65, 'silent': 1}\n",
      "\tScore 0.12456241135949442\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 768.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 2, 'alpha': 0.35000000000000003, 'min_child_weight': 2.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.10962140497578612\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.65, 'n_estimators': 847.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 3, 'alpha': 0.15000000000000002, 'min_child_weight': 3.0, 'gamma': 0.6000000000000001, 'silent': 1}\n",
      "\tScore 0.11421461289308657\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.5, 'n_estimators': 497.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 0.6000000000000001, 'max_depth': 8, 'alpha': 0.0, 'min_child_weight': 4.0, 'gamma': 0.5, 'silent': 1}\n",
      "\tScore 0.11779400935007717\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 696.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 4, 'alpha': 0.25, 'min_child_weight': 2.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.12062611996020113\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.55, 'n_estimators': 617.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 12, 'alpha': 0.30000000000000004, 'min_child_weight': 3.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.12631955228665523\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.6000000000000001, 'n_estimators': 1117.0, 'eval_metric': 'mlogloss', 'eta': 0.4, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 3, 'alpha': 0.15000000000000002, 'min_child_weight': 2.0, 'gamma': 0.65, 'silent': 1}\n",
      "\tScore 0.14535652516940872\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 722.0, 'eval_metric': 'mlogloss', 'eta': 0.25, 'nthread': 6, 'colsample_bytree': 0.8500000000000001, 'max_depth': 3, 'alpha': 0.1, 'min_child_weight': 1.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.10885024819719658\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 672.0, 'eval_metric': 'mlogloss', 'eta': 0.275, 'nthread': 6, 'colsample_bytree': 0.8500000000000001, 'max_depth': 3, 'alpha': 0.05, 'min_child_weight': 1.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.10831187955019043\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9, 'n_estimators': 634.0, 'eval_metric': 'mlogloss', 'eta': 0.2, 'nthread': 6, 'colsample_bytree': 0.8500000000000001, 'max_depth': 3, 'alpha': 0.05, 'min_child_weight': 1.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.11699601533792602\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 770.0, 'eval_metric': 'mlogloss', 'eta': 0.35000000000000003, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 3, 'alpha': 0.2, 'min_child_weight': 1.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.11946225516401429\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 818.0, 'eval_metric': 'mlogloss', 'eta': 0.275, 'nthread': 6, 'colsample_bytree': 0.8, 'max_depth': 3, 'alpha': 0.25, 'min_child_weight': 1.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.10842572857003481\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 595.0, 'eval_metric': 'mlogloss', 'eta': 0.15000000000000002, 'nthread': 6, 'colsample_bytree': 0.8500000000000001, 'max_depth': 3, 'alpha': 0.15000000000000002, 'min_child_weight': 1.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.11374590500271908\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 442.0, 'eval_metric': 'mlogloss', 'eta': 0.225, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 3, 'alpha': 0.1, 'min_child_weight': 1.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.10875636795518726\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 757.0, 'eval_metric': 'mlogloss', 'eta': 0.2, 'nthread': 6, 'colsample_bytree': 0.8500000000000001, 'max_depth': 3, 'alpha': 0.2, 'min_child_weight': 2.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.11663819025107185\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 364.0, 'eval_metric': 'mlogloss', 'eta': 0.17500000000000002, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 3, 'alpha': 0.25, 'min_child_weight': 1.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.10918882518095734\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 665.0, 'eval_metric': 'mlogloss', 'eta': 0.17500000000000002, 'nthread': 6, 'colsample_bytree': 0.8, 'max_depth': 3, 'alpha': 0.0, 'min_child_weight': 1.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.1090022072452345\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 547.0, 'eval_metric': 'mlogloss', 'eta': 0.325, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 3, 'alpha': 0.05, 'min_child_weight': 1.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.11957784108735507\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 471.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 6, 'alpha': 0.1, 'min_child_weight': 1.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.11553356820326936\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 699.0, 'eval_metric': 'mlogloss', 'eta': 0.225, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 7, 'alpha': 0.0, 'min_child_weight': 1.0, 'gamma': 0.65, 'silent': 1}\n",
      "\tScore 0.11431453387253435\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 789.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 3, 'alpha': 0.15000000000000002, 'min_child_weight': 2.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.11317004706032996\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1074.0, 'eval_metric': 'mlogloss', 'eta': 0.30000000000000004, 'nthread': 6, 'colsample_bytree': 0.8500000000000001, 'max_depth': 11, 'alpha': 0.2, 'min_child_weight': 1.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.11597766182487818\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9, 'n_estimators': 930.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 9, 'alpha': 0.30000000000000004, 'min_child_weight': 3.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.11519494840988957\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 654.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 0.75, 'max_depth': 5, 'alpha': 0.1, 'min_child_weight': 2.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.1091189709138804\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 585.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 0.8, 'max_depth': 10, 'alpha': 0.35000000000000003, 'min_child_weight': 1.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.11989021332138186\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 985.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 3, 'alpha': 0.0, 'min_child_weight': 3.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.11745792611337083\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8500000000000001, 'n_estimators': 883.0, 'eval_metric': 'mlogloss', 'eta': 0.375, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 1, 'alpha': 0.15000000000000002, 'min_child_weight': 3.0, 'gamma': 0.65, 'silent': 1}\n",
      "\tScore 0.11821806349071357\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 521.0, 'eval_metric': 'mlogloss', 'eta': 0.15000000000000002, 'nthread': 6, 'colsample_bytree': 0.8500000000000001, 'max_depth': 2, 'alpha': 0.05, 'min_child_weight': 1.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.11062759096139141\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9, 'n_estimators': 301.0, 'eval_metric': 'mlogloss', 'eta': 0.25, 'nthread': 6, 'colsample_bytree': 0.8, 'max_depth': 3, 'alpha': 0.25, 'min_child_weight': 3.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.11271830328878796\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 723.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 8, 'alpha': 0.4, 'min_child_weight': 2.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.11077834685617668\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 840.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 3, 'alpha': 0.2, 'min_child_weight': 1.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.11357986725078871\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 377.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 12, 'alpha': 0.1, 'min_child_weight': 2.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.11398388622145024\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 324.0, 'eval_metric': 'mlogloss', 'eta': 0.17500000000000002, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 4, 'alpha': 0.05, 'min_child_weight': 3.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.11432637783988044\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 482.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 6, 'alpha': 0.0, 'min_child_weight': 6.0, 'gamma': 0.65, 'silent': 1}\n",
      "\tScore 0.11903732498921933\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.65, 'n_estimators': 261.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 3, 'alpha': 0.15000000000000002, 'min_child_weight': 3.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.11224904245730478\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8500000000000001, 'n_estimators': 749.0, 'eval_metric': 'mlogloss', 'eta': 0.275, 'nthread': 6, 'colsample_bytree': 0.7000000000000001, 'max_depth': 11, 'alpha': 0.45, 'min_child_weight': 2.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.12967098980462524\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 405.0, 'eval_metric': 'mlogloss', 'eta': 0.4, 'nthread': 6, 'colsample_bytree': 0.8500000000000001, 'max_depth': 3, 'alpha': 0.25, 'min_child_weight': 2.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.10961083493150452\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 561.0, 'eval_metric': 'mlogloss', 'eta': 0.2, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 7, 'alpha': 0.30000000000000004, 'min_child_weight': 1.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.12630210053377364\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9, 'n_estimators': 610.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 9, 'alpha': 0.2, 'min_child_weight': 3.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.11707764031462978\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 212.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 3, 'alpha': 0.1, 'min_child_weight': 4.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.10857829492979011\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 643.0, 'eval_metric': 'mlogloss', 'eta': 0.30000000000000004, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 5, 'alpha': 0.05, 'min_child_weight': 3.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.13834592100935625\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.65, 'n_estimators': 1045.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 10, 'alpha': 0.4, 'min_child_weight': 2.0, 'gamma': 0.65, 'silent': 1}\n",
      "\tScore 0.12683408050829836\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 1294.0, 'eval_metric': 'mlogloss', 'eta': 0.15000000000000002, 'nthread': 6, 'colsample_bytree': 0.8500000000000001, 'max_depth': 1, 'alpha': 0.15000000000000002, 'min_child_weight': 4.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.11741661581988896\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.6000000000000001, 'n_estimators': 858.0, 'eval_metric': 'mlogloss', 'eta': 0.35000000000000003, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 3, 'alpha': 0.5, 'min_child_weight': 1.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.13052298687288985\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 456.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 2, 'alpha': 0.0, 'min_child_weight': 3.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.10930511395404854\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 520.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 3, 'alpha': 0.05, 'min_child_weight': 2.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.1101145983141971\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8500000000000001, 'n_estimators': 341.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 8, 'alpha': 0.15000000000000002, 'min_child_weight': 3.0, 'gamma': 0.65, 'silent': 1}\n",
      "\tScore 0.12056633587610245\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.55, 'n_estimators': 273.0, 'eval_metric': 'mlogloss', 'eta': 0.2, 'nthread': 6, 'colsample_bytree': 0.8500000000000001, 'max_depth': 3, 'alpha': 0.6000000000000001, 'min_child_weight': 1.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.11030517969681293\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9, 'n_estimators': 914.0, 'eval_metric': 'mlogloss', 'eta': 0.45, 'nthread': 6, 'colsample_bytree': 0.8, 'max_depth': 3, 'alpha': 0.1, 'min_child_weight': 4.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.12360012812087036\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 812.0, 'eval_metric': 'mlogloss', 'eta': 0.325, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 6, 'alpha': 0.2, 'min_child_weight': 3.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.10977447671711037\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 1350.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 12, 'alpha': 0.30000000000000004, 'min_child_weight': 2.0, 'gamma': 0.7000000000000001, 'silent': 1}\n",
      "\tScore 0.12672623874759664\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 433.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.75, 'max_depth': 3, 'alpha': 0.35000000000000003, 'min_child_weight': 3.0, 'gamma': 0.65, 'silent': 1}\n",
      "\tScore 0.11069081881789965\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.65, 'n_estimators': 497.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 4, 'alpha': 0.55, 'min_child_weight': 1.0, 'gamma': 0.6000000000000001, 'silent': 1}\n",
      "\tScore 0.11307661486900827\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 232.0, 'eval_metric': 'mlogloss', 'eta': 0.225, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 11, 'alpha': 0.1, 'min_child_weight': 2.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.1312466130413703\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 1448.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 0.8500000000000001, 'max_depth': 7, 'alpha': 0.0, 'min_child_weight': 4.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.12452298680360115\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 1015.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 9, 'alpha': 0.45, 'min_child_weight': 1.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.11702014344297512\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1210.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 3, 'alpha': 0.05, 'min_child_weight': 3.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.10765081253608051\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 1222.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 5, 'alpha': 0.0, 'min_child_weight': 3.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.12656099353573286\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.55, 'n_estimators': 1209.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 10, 'alpha': 0.05, 'min_child_weight': 3.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.1358479856054403\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 1393.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 3, 'alpha': 0.0, 'min_child_weight': 3.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.11312700974887814\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8500000000000001, 'n_estimators': 1347.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 2, 'alpha': 0.05, 'min_child_weight': 4.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.10992675190948327\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.6000000000000001, 'n_estimators': 1171.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 3, 'alpha': 0.05, 'min_child_weight': 3.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.10914904872709809\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 1304.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 1, 'alpha': 0.65, 'min_child_weight': 3.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.11547085307537526\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.5, 'n_estimators': 1258.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 8, 'alpha': 0.55, 'min_child_weight': 4.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.13048441332710933\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.65, 'n_estimators': 1496.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 3, 'alpha': 0.1, 'min_child_weight': 3.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.10971359400447543\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 1148.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 12, 'alpha': 0.0, 'min_child_weight': 3.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.1349802420042124\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9, 'n_estimators': 1376.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 0.65, 'max_depth': 4, 'alpha': 0.15000000000000002, 'min_child_weight': 4.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.11323282726275573\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1407.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 3, 'alpha': 0.5, 'min_child_weight': 3.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.10780705268481339\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.65, 'n_estimators': 1239.0, 'eval_metric': 'mlogloss', 'eta': 0.15000000000000002, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 6, 'alpha': 0.5, 'min_child_weight': 3.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.12792420023208173\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 1473.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 3, 'alpha': 0.5, 'min_child_weight': 4.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.11701336766743789\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 1455.0, 'eval_metric': 'mlogloss', 'eta': 0.17500000000000002, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 11, 'alpha': 0.6000000000000001, 'min_child_weight': 3.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.12656615584391276\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8500000000000001, 'n_estimators': 1329.0, 'eval_metric': 'mlogloss', 'eta': 0.15000000000000002, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 3, 'alpha': 0.45, 'min_child_weight': 3.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.11723006736799121\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.6000000000000001, 'n_estimators': 1424.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 7, 'alpha': 0.4, 'min_child_weight': 3.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.13271103636818551\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 1415.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 9, 'alpha': 0.55, 'min_child_weight': 4.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.11821285911626675\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 1498.0, 'eval_metric': 'mlogloss', 'eta': 0.15000000000000002, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 3, 'alpha': 0.6000000000000001, 'min_child_weight': 3.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.11737479731537828\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1383.0, 'eval_metric': 'mlogloss', 'eta': 0.17500000000000002, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 5, 'alpha': 0.7000000000000001, 'min_child_weight': 3.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.10848520215562403\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 1295.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 10, 'alpha': 0.5, 'min_child_weight': 4.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.1251093060883121\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 147.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 1, 'alpha': 0.45, 'min_child_weight': 3.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.12855833394089208\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9, 'n_estimators': 1367.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 3, 'alpha': 0.65, 'min_child_weight': 4.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.1126677326669175\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.65, 'n_estimators': 1466.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 3, 'alpha': 0.6000000000000001, 'min_child_weight': 3.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.115562400727725\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8500000000000001, 'n_estimators': 1125.0, 'eval_metric': 'mlogloss', 'eta': 0.15000000000000002, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 8, 'alpha': 0.55, 'min_child_weight': 3.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.12042305237888647\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 193.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 2, 'alpha': 0.4, 'min_child_weight': 4.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.11182756911738562\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1073.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 0.7000000000000001, 'max_depth': 12, 'alpha': 0.5, 'min_child_weight': 2.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.11025863456054472\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 1417.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 3, 'alpha': 0.45, 'min_child_weight': 3.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.11780406377987293\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.6000000000000001, 'n_estimators': 969.0, 'eval_metric': 'mlogloss', 'eta': 0.17500000000000002, 'nthread': 6, 'colsample_bytree': 0.5, 'max_depth': 4, 'alpha': 0.55, 'min_child_weight': 3.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.11982728437875854\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.5, 'n_estimators': 1327.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 6, 'alpha': 0.65, 'min_child_weight': 2.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.1236721035160906\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 1283.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 3, 'alpha': 0.4, 'min_child_weight': 4.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.11242023933420757\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.55, 'n_estimators': 1202.0, 'eval_metric': 'mlogloss', 'eta': 0.15000000000000002, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 11, 'alpha': 0.5, 'min_child_weight': 3.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.13461640242243195\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 1102.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 3, 'alpha': 0.7000000000000001, 'min_child_weight': 2.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.11220416967657605\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 116.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 7, 'alpha': 0.6000000000000001, 'min_child_weight': 6.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.11154821961709327\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9, 'n_estimators': 366.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 3, 'alpha': 0.35000000000000003, 'min_child_weight': 3.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.10809188409697036\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1156.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 0.6000000000000001, 'max_depth': 9, 'alpha': 0.55, 'min_child_weight': 4.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.10961425127900398\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.65, 'n_estimators': 331.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 5, 'alpha': 0.45, 'min_child_weight': 3.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.10903286029346808\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 285.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 1, 'alpha': 0.65, 'min_child_weight': 2.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.11675926531846888\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.6000000000000001, 'n_estimators': 304.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 10, 'alpha': 0.6000000000000001, 'min_child_weight': 3.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.11706485568889968\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 1237.0, 'eval_metric': 'mlogloss', 'eta': 0.15000000000000002, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 3, 'alpha': 0.75, 'min_child_weight': 4.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.11199589541263566\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 241.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 0.55, 'max_depth': 2, 'alpha': 0.7000000000000001, 'min_child_weight': 3.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.11235220564002625\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.65, 'n_estimators': 1441.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 3, 'alpha': 0.5, 'min_child_weight': 5.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.11279493930138136\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 392.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 8, 'alpha': 0.9500000000000001, 'min_child_weight': 2.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.10855774352563631\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8500000000000001, 'n_estimators': 183.0, 'eval_metric': 'mlogloss', 'eta': 0.2, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 3, 'alpha': 0.35000000000000003, 'min_child_weight': 3.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.11003702894030945\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 133.0, 'eval_metric': 'mlogloss', 'eta': 0.15000000000000002, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 12, 'alpha': 0.55, 'min_child_weight': 4.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.11797083746692429\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9, 'n_estimators': 1043.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 4, 'alpha': 0.6000000000000001, 'min_child_weight': 3.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.1126525426871316\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.55, 'n_estimators': 218.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 0.65, 'max_depth': 6, 'alpha': 0.45, 'min_child_weight': 2.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.10836127016679922\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 1402.0, 'eval_metric': 'mlogloss', 'eta': 0.17500000000000002, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 3, 'alpha': 0.45, 'min_child_weight': 3.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.12164477894513179\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1345.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 11, 'alpha': 0.75, 'min_child_weight': 4.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.11110884278853461\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 1494.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 3, 'alpha': 0.4, 'min_child_weight': 2.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.10891130153231465\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.6000000000000001, 'n_estimators': 1000.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 7, 'alpha': 0.65, 'min_child_weight': 3.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.12470533286043456\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 257.0, 'eval_metric': 'mlogloss', 'eta': 0.17500000000000002, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 3, 'alpha': 0.4, 'min_child_weight': 3.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.11029528519067211\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 1184.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 9, 'alpha': 0.55, 'min_child_weight': 2.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.1242786336475153\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.65, 'n_estimators': 1307.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 5, 'alpha': 0.8, 'min_child_weight': 3.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.11940722081958952\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.75, 'n_estimators': 108.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 10, 'alpha': 0.5, 'min_child_weight': 4.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.1130996055033373\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.5, 'n_estimators': 154.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 3, 'alpha': 0.65, 'min_child_weight': 3.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.13215837400656824\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8500000000000001, 'n_estimators': 1276.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 0.7000000000000001, 'max_depth': 1, 'alpha': 0.6000000000000001, 'min_child_weight': 2.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.11562722542008305\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 425.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 2, 'alpha': 0.35000000000000003, 'min_child_weight': 5.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.11114940340064061\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.7000000000000001, 'n_estimators': 1216.0, 'eval_metric': 'mlogloss', 'eta': 0.15000000000000002, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 3, 'alpha': 0.8500000000000001, 'min_child_weight': 4.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.11448012088038031\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.55, 'n_estimators': 937.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 8, 'alpha': 0.55, 'min_child_weight': 3.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.12683627515025583\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.65, 'n_estimators': 882.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 3, 'alpha': 0.5, 'min_child_weight': 3.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.11282570932606889\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.8, 'n_estimators': 1093.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 12, 'alpha': 0.7000000000000001, 'min_child_weight': 2.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.11926359807453708\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9, 'n_estimators': 1474.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 3, 'alpha': 0.30000000000000004, 'min_child_weight': 4.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.11499380054253958\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 358.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 4, 'alpha': 0.9, 'min_child_weight': 3.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.10765833187041211\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 183.0, 'eval_metric': 'mlogloss', 'eta': 0.17500000000000002, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 4, 'alpha': 0.9500000000000001, 'min_child_weight': 3.0, 'gamma': 0.75, 'silent': 1}\n",
      "\tScore 0.10792430093248405\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 218.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.75, 'max_depth': 4, 'alpha': 0.9, 'min_child_weight': 3.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.11874808382180725\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 304.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 4, 'alpha': 0.9, 'min_child_weight': 3.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.10800256748700675\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 153.0, 'eval_metric': 'mlogloss', 'eta': 0.2, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 4, 'alpha': 0.05, 'min_child_weight': 3.0, 'gamma': 0.8, 'silent': 1}\n",
      "\tScore 0.11162311761664018\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 357.0, 'eval_metric': 'mlogloss', 'eta': 0.225, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 4, 'alpha': 0.9500000000000001, 'min_child_weight': 3.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.10809174701440484\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 275.0, 'eval_metric': 'mlogloss', 'eta': 0.25, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 4, 'alpha': 1.0, 'min_child_weight': 3.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.11129189825528932\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 202.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 4, 'alpha': 0.8500000000000001, 'min_child_weight': 3.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.10767590022410307\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 114.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.6000000000000001, 'max_depth': 4, 'alpha': 0.9500000000000001, 'min_child_weight': 3.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.18520632159505493\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 242.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 4, 'alpha': 1.0, 'min_child_weight': 3.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.10813097853252691\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 325.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.5, 'max_depth': 4, 'alpha': 0.8500000000000001, 'min_child_weight': 3.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.11754786129499417\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 200.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 4, 'alpha': 1.0, 'min_child_weight': 3.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.11468271438755473\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 142.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 4, 'alpha': 0.9, 'min_child_weight': 3.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.10759183969293161\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 160.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 4, 'alpha': 0.9, 'min_child_weight': 3.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.10808054157323123\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 128.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 4, 'alpha': 0.8500000000000001, 'min_child_weight': 4.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.1111753894249915\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1360.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 4, 'alpha': 0.9500000000000001, 'min_child_weight': 3.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.10791074316958181\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 101.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 0.65, 'max_depth': 4, 'alpha': 0.9, 'min_child_weight': 3.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.10800870599675155\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1402.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 4, 'alpha': 1.0, 'min_child_weight': 4.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.10810938293186118\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 192.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 4, 'alpha': 0.8, 'min_child_weight': 3.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.10863939449163718\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1446.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 4, 'alpha': 0.8500000000000001, 'min_child_weight': 3.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.10771344603345208\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 385.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 4, 'alpha': 0.8500000000000001, 'min_child_weight': 4.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.10846189493012601\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 102.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 4, 'alpha': 0.8, 'min_child_weight': 3.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.11392430456715062\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 265.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 4, 'alpha': 0.9, 'min_child_weight': 3.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.11071410339606504\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 100.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 4, 'alpha': 0.9500000000000001, 'min_child_weight': 3.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.18585815873082712\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 294.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 4, 'alpha': 0.9500000000000001, 'min_child_weight': 4.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.10852899139578867\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 164.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 4, 'alpha': 0.9, 'min_child_weight': 3.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.10799906435315819\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 136.0, 'eval_metric': 'mlogloss', 'eta': 0.45, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 4, 'alpha': 0.8500000000000001, 'min_child_weight': 2.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.11122903291470768\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 1446.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 4, 'alpha': 1.0, 'min_child_weight': 4.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.10927144697563076\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1499.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 4, 'alpha': 0.8, 'min_child_weight': 3.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.10795364058961147\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 343.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.6000000000000001, 'max_depth': 4, 'alpha': 0.8500000000000001, 'min_child_weight': 3.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.10993871652409633\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9, 'n_estimators': 1168.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 4, 'alpha': 0.9, 'min_child_weight': 3.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.10873692576783658\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1129.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 4, 'alpha': 0.75, 'min_child_weight': 2.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.10784499945837571\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1321.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 4, 'alpha': 0.9, 'min_child_weight': 3.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.10800502238660188\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1382.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 4, 'alpha': 0.8, 'min_child_weight': 3.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.1078527610275276\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1420.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 4, 'alpha': 0.8500000000000001, 'min_child_weight': 3.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.10791898907298493\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1483.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 4, 'alpha': 0.9500000000000001, 'min_child_weight': 3.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.10775950986369152\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1463.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 4, 'alpha': 1.0, 'min_child_weight': 3.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.10812108136222524\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 1492.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 4, 'alpha': 0.9500000000000001, 'min_child_weight': 3.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.11138448653587091\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 1443.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 4, 'alpha': 0.9500000000000001, 'min_child_weight': 3.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.11040031882171478\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1281.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 4, 'alpha': 0.9, 'min_child_weight': 3.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.10794561544581428\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1330.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 4, 'alpha': 1.0, 'min_child_weight': 3.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.10821384845656154\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 1492.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 4, 'alpha': 0.8, 'min_child_weight': 3.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.11114503288711955\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1379.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 4, 'alpha': 1.0, 'min_child_weight': 3.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.10790645772088728\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1359.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 4, 'alpha': 0.8500000000000001, 'min_child_weight': 3.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.10826635273504215\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 1232.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 4, 'alpha': 0.9, 'min_child_weight': 3.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.10887424483510959\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1262.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 4, 'alpha': 0.8500000000000001, 'min_child_weight': 3.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.10761884463554662\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9, 'n_estimators': 1243.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 4, 'alpha': 0.75, 'min_child_weight': 3.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.11219050863314471\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 1211.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 4, 'alpha': 0.8, 'min_child_weight': 3.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.11074634324448279\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1268.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 4, 'alpha': 0.8500000000000001, 'min_child_weight': 3.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.10769366046280802\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 1070.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 4, 'alpha': 0.9, 'min_child_weight': 3.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.11150140339662154\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1190.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 4, 'alpha': 0.8, 'min_child_weight': 3.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.10785276115917355\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1153.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 4, 'alpha': 0.8500000000000001, 'min_child_weight': 3.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.1079292969738523\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 1266.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 4, 'alpha': 0.75, 'min_child_weight': 4.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.11242560655292899\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9, 'n_estimators': 1126.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 4, 'alpha': 0.8, 'min_child_weight': 3.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.11390919191289116\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 1045.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 4, 'alpha': 0.9, 'min_child_weight': 2.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.10855589181265451\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1282.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 4, 'alpha': 0.9500000000000001, 'min_child_weight': 3.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.10784979913947816\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1198.0, 'eval_metric': 'mlogloss', 'eta': 0.15000000000000002, 'nthread': 6, 'colsample_bytree': 0.55, 'max_depth': 4, 'alpha': 0.8500000000000001, 'min_child_weight': 3.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.10905083806974634\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 1106.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 4, 'alpha': 0.8500000000000001, 'min_child_weight': 4.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.11140453092536673\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1156.0, 'eval_metric': 'mlogloss', 'eta': 0.15000000000000002, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 4, 'alpha': 0.75, 'min_child_weight': 2.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.10820649555374733\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 1013.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 4, 'alpha': 1.0, 'min_child_weight': 3.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.11003636686161025\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9, 'n_estimators': 1241.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 6, 'alpha': 0.8, 'min_child_weight': 3.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.1150924958226711\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1318.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 11, 'alpha': 0.9500000000000001, 'min_child_weight': 4.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.11002249288153478\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 1095.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 7, 'alpha': 0.9, 'min_child_weight': 3.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.11423239624251201\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1181.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 9, 'alpha': 0.8, 'min_child_weight': 2.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.10902714201865396\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1302.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 4, 'alpha': 0.8500000000000001, 'min_child_weight': 3.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.10771344766160286\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9, 'n_estimators': 968.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 1, 'alpha': 0.9500000000000001, 'min_child_weight': 4.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.11569119362208947\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9, 'n_estimators': 1262.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 5, 'alpha': 0.9, 'min_child_weight': 3.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.11265048100416133\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 1222.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 10, 'alpha': 1.0, 'min_child_weight': 3.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.1157896097517715\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1131.0, 'eval_metric': 'mlogloss', 'eta': 0.025, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 4, 'alpha': 0.8500000000000001, 'min_child_weight': 2.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.10791323869724702\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 1035.0, 'eval_metric': 'mlogloss', 'eta': 0.47500000000000003, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 2, 'alpha': 0.75, 'min_child_weight': 3.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.11010409586234655\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1085.0, 'eval_metric': 'mlogloss', 'eta': 0.05, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 8, 'alpha': 0.8, 'min_child_weight': 4.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.10914170100021126\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 1349.0, 'eval_metric': 'mlogloss', 'eta': 0.375, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 4, 'alpha': 0.9500000000000001, 'min_child_weight': 3.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.11608311453998352\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1220.0, 'eval_metric': 'mlogloss', 'eta': 0.07500000000000001, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 12, 'alpha': 0.75, 'min_child_weight': 3.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.11035879960150494\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 1309.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 4, 'alpha': 0.9, 'min_child_weight': 2.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.11224158291061628\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1057.0, 'eval_metric': 'mlogloss', 'eta': 0.15000000000000002, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 6, 'alpha': 0.9, 'min_child_weight': 3.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.10766922479519878\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 1055.0, 'eval_metric': 'mlogloss', 'eta': 0.15000000000000002, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 6, 'alpha': 1.0, 'min_child_weight': 4.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.11305552530579127\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1000.0, 'eval_metric': 'mlogloss', 'eta': 0.17500000000000002, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 6, 'alpha': 0.9500000000000001, 'min_child_weight': 3.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.10761815123641165\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 994.0, 'eval_metric': 'mlogloss', 'eta': 0.2, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 6, 'alpha': 0.9500000000000001, 'min_child_weight': 2.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.1085570250364245\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9, 'n_estimators': 930.0, 'eval_metric': 'mlogloss', 'eta': 0.17500000000000002, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 6, 'alpha': 1.0, 'min_child_weight': 3.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.11384664575284124\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 898.0, 'eval_metric': 'mlogloss', 'eta': 0.225, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 6, 'alpha': 1.0, 'min_child_weight': 3.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.11394893508000058\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1022.0, 'eval_metric': 'mlogloss', 'eta': 0.17500000000000002, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 6, 'alpha': 0.9500000000000001, 'min_child_weight': 3.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.1076181512209239\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9, 'n_estimators': 953.0, 'eval_metric': 'mlogloss', 'eta': 0.25, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 6, 'alpha': 0.9500000000000001, 'min_child_weight': 4.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.1157182413322795\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1002.0, 'eval_metric': 'mlogloss', 'eta': 0.225, 'nthread': 6, 'colsample_bytree': 0.5, 'max_depth': 6, 'alpha': 0.9500000000000001, 'min_child_weight': 4.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.10902150059415275\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 865.0, 'eval_metric': 'mlogloss', 'eta': 0.2, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 6, 'alpha': 1.0, 'min_child_weight': 2.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.11366527094730179\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1023.0, 'eval_metric': 'mlogloss', 'eta': 0.275, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 6, 'alpha': 1.0, 'min_child_weight': 3.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.10883452907694277\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 908.0, 'eval_metric': 'mlogloss', 'eta': 0.25, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 6, 'alpha': 0.9, 'min_child_weight': 3.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.11491178331207434\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1111.0, 'eval_metric': 'mlogloss', 'eta': 0.17500000000000002, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 6, 'alpha': 1.0, 'min_child_weight': 3.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.1079071401130723\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9, 'n_estimators': 984.0, 'eval_metric': 'mlogloss', 'eta': 0.2, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 6, 'alpha': 0.9500000000000001, 'min_child_weight': 2.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.1146006181718138\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 953.0, 'eval_metric': 'mlogloss', 'eta': 0.17500000000000002, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 6, 'alpha': 0.9, 'min_child_weight': 3.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.11393760902860976\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1166.0, 'eval_metric': 'mlogloss', 'eta': 0.225, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 6, 'alpha': 0.9500000000000001, 'min_child_weight': 4.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.10791426097768606\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 973.0, 'eval_metric': 'mlogloss', 'eta': 0.2, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 6, 'alpha': 1.0, 'min_child_weight': 2.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.11449146602042458\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 830.0, 'eval_metric': 'mlogloss', 'eta': 0.17500000000000002, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 6, 'alpha': 0.9500000000000001, 'min_child_weight': 3.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.10814116763136174\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 1019.0, 'eval_metric': 'mlogloss', 'eta': 0.225, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 6, 'alpha': 0.9, 'min_child_weight': 3.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.11562279785708568\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1091.0, 'eval_metric': 'mlogloss', 'eta': 0.25, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 6, 'alpha': 0.8500000000000001, 'min_child_weight': 4.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.11019438141248179\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1063.0, 'eval_metric': 'mlogloss', 'eta': 0.17500000000000002, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 6, 'alpha': 1.0, 'min_child_weight': 3.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.107907140132432\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9, 'n_estimators': 796.0, 'eval_metric': 'mlogloss', 'eta': 0.15000000000000002, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 6, 'alpha': 0.9500000000000001, 'min_child_weight': 3.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.11418550252100323\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 890.0, 'eval_metric': 'mlogloss', 'eta': 0.2, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 6, 'alpha': 0.9, 'min_child_weight': 2.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.11474727063153482\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 924.0, 'eval_metric': 'mlogloss', 'eta': 0.275, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 6, 'alpha': 0.8500000000000001, 'min_child_weight': 3.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.10854832946267623\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1142.0, 'eval_metric': 'mlogloss', 'eta': 0.225, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 11, 'alpha': 0.9, 'min_child_weight': 3.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.1106920754016165\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 840.0, 'eval_metric': 'mlogloss', 'eta': 0.15000000000000002, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 6, 'alpha': 0.9500000000000001, 'min_child_weight': 4.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.1134615692850946\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1080.0, 'eval_metric': 'mlogloss', 'eta': 0.17500000000000002, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 5, 'alpha': 0.8, 'min_child_weight': 3.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.10843507271164722\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9, 'n_estimators': 1113.0, 'eval_metric': 'mlogloss', 'eta': 0.15000000000000002, 'nthread': 6, 'colsample_bytree': 0.55, 'max_depth': 7, 'alpha': 0.8500000000000001, 'min_child_weight': 2.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.11441225494462058\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 1185.0, 'eval_metric': 'mlogloss', 'eta': 0.30000000000000004, 'nthread': 6, 'colsample_bytree': 0.7000000000000001, 'max_depth': 10, 'alpha': 1.0, 'min_child_weight': 3.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.11659196473415041\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 997.0, 'eval_metric': 'mlogloss', 'eta': 0.25, 'nthread': 6, 'colsample_bytree': 0.65, 'max_depth': 1, 'alpha': 0.8, 'min_child_weight': 4.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.11689446380692724\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 1041.0, 'eval_metric': 'mlogloss', 'eta': 0.2, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 2, 'alpha': 0.9, 'min_child_weight': 2.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.1087944739295116\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9, 'n_estimators': 868.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 9, 'alpha': 0.9500000000000001, 'min_child_weight': 3.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.11600471965724014\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1150.0, 'eval_metric': 'mlogloss', 'eta': 0.17500000000000002, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 8, 'alpha': 0.9, 'min_child_weight': 3.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.10908429145347025\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 962.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 6, 'alpha': 0.75, 'min_child_weight': 3.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.1145525576280099\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1120.0, 'eval_metric': 'mlogloss', 'eta': 0.15000000000000002, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 12, 'alpha': 1.0, 'min_child_weight': 4.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.11057797696504663\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1201.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 6, 'alpha': 0.8500000000000001, 'min_child_weight': 3.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.10896259577751141\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9, 'n_estimators': 939.0, 'eval_metric': 'mlogloss', 'eta': 0.2, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 5, 'alpha': 0.7000000000000001, 'min_child_weight': 2.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.1147206581486371\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 1027.0, 'eval_metric': 'mlogloss', 'eta': 0.15000000000000002, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 11, 'alpha': 1.0, 'min_child_weight': 3.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.1159826649590053\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1072.0, 'eval_metric': 'mlogloss', 'eta': 0.275, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 7, 'alpha': 0.9500000000000001, 'min_child_weight': 4.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.10989133156573543\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 772.0, 'eval_metric': 'mlogloss', 'eta': 0.17500000000000002, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 9, 'alpha': 0.8, 'min_child_weight': 3.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.11702195250335659\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 985.0, 'eval_metric': 'mlogloss', 'eta': 0.2, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 10, 'alpha': 0.8500000000000001, 'min_child_weight': 3.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.11101378588260466\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 903.0, 'eval_metric': 'mlogloss', 'eta': 0.225, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 6, 'alpha': 0.9, 'min_child_weight': 3.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.11443395380823429\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9, 'n_estimators': 1252.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 1, 'alpha': 0.9500000000000001, 'min_child_weight': 2.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.11575422990936403\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1170.0, 'eval_metric': 'mlogloss', 'eta': 0.15000000000000002, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 2, 'alpha': 0.9500000000000001, 'min_child_weight': 4.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.11135904337168936\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 814.0, 'eval_metric': 'mlogloss', 'eta': 0.25, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 6, 'alpha': 1.0, 'min_child_weight': 3.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.10956727070098891\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 1133.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 8, 'alpha': 0.7000000000000001, 'min_child_weight': 2.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.116228401566984\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 742.0, 'eval_metric': 'mlogloss', 'eta': 0.17500000000000002, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 12, 'alpha': 0.8, 'min_child_weight': 3.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.11023183030863146\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 1097.0, 'eval_metric': 'mlogloss', 'eta': 0.30000000000000004, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 11, 'alpha': 0.9, 'min_child_weight': 3.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.12000578306223678\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1219.0, 'eval_metric': 'mlogloss', 'eta': 0.225, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 6, 'alpha': 0.8500000000000001, 'min_child_weight': 4.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.11027834622315134\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 1008.0, 'eval_metric': 'mlogloss', 'eta': 0.17500000000000002, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 9, 'alpha': 1.0, 'min_child_weight': 2.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.11591303597050992\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9, 'n_estimators': 1035.0, 'eval_metric': 'mlogloss', 'eta': 0.15000000000000002, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 7, 'alpha': 0.9, 'min_child_weight': 3.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.11481950256456908\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 871.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 5, 'alpha': 0.75, 'min_child_weight': 3.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.10776087354259244\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 947.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 0.9, 'max_depth': 10, 'alpha': 0.9500000000000001, 'min_child_weight': 3.0, 'gamma': 0.9, 'silent': 1}\n",
      "\tScore 0.109783600021644\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 1293.0, 'eval_metric': 'mlogloss', 'eta': 0.2, 'nthread': 6, 'colsample_bytree': 0.9500000000000001, 'max_depth': 1, 'alpha': 0.8500000000000001, 'min_child_weight': 4.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.11584237791175998\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 1.0, 'n_estimators': 1248.0, 'eval_metric': 'mlogloss', 'eta': 0.1, 'nthread': 6, 'colsample_bytree': 0.75, 'max_depth': 6, 'alpha': 0.8, 'min_child_weight': 2.0, 'gamma': 0.9500000000000001, 'silent': 1}\n",
      "\tScore 0.10830796907065242\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9, 'n_estimators': 1067.0, 'eval_metric': 'mlogloss', 'eta': 0.325, 'nthread': 6, 'colsample_bytree': 1.0, 'max_depth': 2, 'alpha': 1.0, 'min_child_weight': 3.0, 'gamma': 1.0, 'silent': 1}\n",
      "\tScore 0.10975076888197836\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'objective': 'multi:softprob', 'num_class': 4, 'subsample': 0.9500000000000001, 'n_estimators': 1205.0, 'eval_metric': 'mlogloss', 'eta': 0.125, 'nthread': 6, 'colsample_bytree': 0.6000000000000001, 'max_depth': 12, 'alpha': 0.9, 'min_child_weight': 3.0, 'gamma': 0.8500000000000001, 'silent': 1}\n",
      "\tScore 0.11659316203715905\n",
      "\n",
      "\n",
      "{'eta': 0.07500000000000001, 'max_depth': 3, 'alpha': 0.9, 'min_child_weight': 3.0, 'colsample_bytree': 1.0, 'gamma': 0.9500000000000001, 'subsample': 0.9500000000000001, 'n_estimators': 142.0}\n"
     ]
    }
   ],
   "source": [
    "#Trials object where the history of search will be stored\n",
    "trials = Trials()\n",
    "optimize(trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': [0.9],\n",
       " 'colsample_bytree': [1.0],\n",
       " 'eta': [0.07500000000000001],\n",
       " 'gamma': [0.9500000000000001],\n",
       " 'max_depth': [3],\n",
       " 'min_child_weight': [3.0],\n",
       " 'n_estimators': [142.0],\n",
       " 'subsample': [0.9500000000000001]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = trials.best_trial['misc']['vals']\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'objective': 'multi:softprob',\n",
    "          'booster': 'gbtree',\n",
    "          'eval_metric' : 'mlogloss',\n",
    "          'nthread': 4,\n",
    "          'silent': 1,\n",
    "          'gamma': 0.9500000000000001,\n",
    "          'alpha': 0.9,\n",
    "          'num_class' : 4,\n",
    "          'min_child_weight': 3.0,\n",
    "          'max_depth': 3,\n",
    "          'subsample': 0.9500000000000001,\n",
    "          \"colsample_bytree\": 1.0,\n",
    "          'eta': 0.07500000000000001,\n",
    "          'verbose_eval': True,\n",
    "          'seed': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.25258\ttest-mlogloss:1.25282\n",
      "[20]\ttrain-mlogloss:0.309275\ttest-mlogloss:0.311644\n",
      "[40]\ttrain-mlogloss:0.147285\ttest-mlogloss:0.151308\n",
      "[60]\ttrain-mlogloss:0.1127\ttest-mlogloss:0.118135\n",
      "[80]\ttrain-mlogloss:0.103601\ttest-mlogloss:0.110269\n",
      "[100]\ttrain-mlogloss:0.100036\ttest-mlogloss:0.107779\n",
      "[120]\ttrain-mlogloss:0.097666\ttest-mlogloss:0.106692\n",
      "[140]\ttrain-mlogloss:0.0956753\ttest-mlogloss:0.106056\n",
      "[160]\ttrain-mlogloss:0.0939183\ttest-mlogloss:0.105624\n",
      "[180]\ttrain-mlogloss:0.092418\ttest-mlogloss:0.105272\n",
      "[200]\ttrain-mlogloss:0.0913397\ttest-mlogloss:0.105217\n",
      "[220]\ttrain-mlogloss:0.090296\ttest-mlogloss:0.105151\n",
      "[240]\ttrain-mlogloss:0.0893537\ttest-mlogloss:0.105082\n",
      "[260]\ttrain-mlogloss:0.0885067\ttest-mlogloss:0.105025\n"
     ]
    }
   ],
   "source": [
    "X, y = train, target\n",
    "dtrain = xgb.DMatrix(X, label= y )\n",
    "dtest = xgb.DMatrix(test)\n",
    "num_rounds = 2000\n",
    "cv_output = xgb.cv(params, dtrain, num_boost_round=num_rounds, early_stopping_rounds=10, verbose_eval=20, show_stdv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tdtrain-mlogloss:1.25262\n",
      "[20]\tdtrain-mlogloss:0.309792\n",
      "[40]\tdtrain-mlogloss:0.148108\n",
      "[60]\tdtrain-mlogloss:0.113623\n",
      "[80]\tdtrain-mlogloss:0.104832\n",
      "[100]\tdtrain-mlogloss:0.101425\n",
      "[120]\tdtrain-mlogloss:0.099365\n",
      "[140]\tdtrain-mlogloss:0.097488\n",
      "[160]\tdtrain-mlogloss:0.095968\n",
      "[180]\tdtrain-mlogloss:0.094718\n",
      "[200]\tdtrain-mlogloss:0.093571\n",
      "[220]\tdtrain-mlogloss:0.092674\n",
      "[240]\tdtrain-mlogloss:0.091762\n",
      "[260]\tdtrain-mlogloss:0.091048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.676063060760498"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rounds = len(cv_output)\n",
    "watchlist = [(dtrain, 'dtrain')]\n",
    "t1= time.time()\n",
    "clf_xgb_main = xgb.train(dtrain=dtrain, params=params, num_boost_round=num_rounds, evals=watchlist, verbose_eval=20)\n",
    "preds_price = clf_xgb_main.predict(dtest)\n",
    "time.time() - t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1f042722630>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcoAAAEWCAYAAADmYNeIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmWXhRGlmZpaFE6WZmVkWTpRmZmZZ/H++g2SFXHmRfgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f042719518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb.plot_importance(clf_xgb_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tdtrain-mlogloss:1.25268\n",
      "[100]\tdtrain-mlogloss:0.101395\n",
      "[200]\tdtrain-mlogloss:0.093806\n",
      "[300]\tdtrain-mlogloss:0.09085\n",
      "[400]\tdtrain-mlogloss:0.088991\n",
      "[500]\tdtrain-mlogloss:0.087545\n",
      "[600]\tdtrain-mlogloss:0.086495\n",
      "[700]\tdtrain-mlogloss:0.085639\n",
      "[800]\tdtrain-mlogloss:0.084912\n",
      "[900]\tdtrain-mlogloss:0.084133\n",
      "[1000]\tdtrain-mlogloss:0.083477\n",
      "[1100]\tdtrain-mlogloss:0.083004\n",
      "[1200]\tdtrain-mlogloss:0.082565\n",
      "[1300]\tdtrain-mlogloss:0.082149\n",
      "[1400]\tdtrain-mlogloss:0.081736\n",
      "[1500]\tdtrain-mlogloss:0.081389\n",
      "[1600]\tdtrain-mlogloss:0.081033\n",
      "[1700]\tdtrain-mlogloss:0.080678\n",
      "[1800]\tdtrain-mlogloss:0.080421\n",
      "[1900]\tdtrain-mlogloss:0.080168\n",
      "1 58.912219524383545\n",
      "[0]\tdtrain-mlogloss:1.25263\n",
      "[100]\tdtrain-mlogloss:0.101444\n",
      "[200]\tdtrain-mlogloss:0.093897\n",
      "[300]\tdtrain-mlogloss:0.090859\n",
      "[400]\tdtrain-mlogloss:0.088949\n",
      "[500]\tdtrain-mlogloss:0.087435\n",
      "[600]\tdtrain-mlogloss:0.086262\n",
      "[700]\tdtrain-mlogloss:0.085245\n",
      "[800]\tdtrain-mlogloss:0.084541\n",
      "[900]\tdtrain-mlogloss:0.083852\n",
      "[1000]\tdtrain-mlogloss:0.083293\n",
      "[1100]\tdtrain-mlogloss:0.082714\n",
      "[1200]\tdtrain-mlogloss:0.082349\n",
      "[1300]\tdtrain-mlogloss:0.08191\n",
      "[1400]\tdtrain-mlogloss:0.081564\n",
      "[1500]\tdtrain-mlogloss:0.081202\n",
      "[1600]\tdtrain-mlogloss:0.08084\n",
      "[1700]\tdtrain-mlogloss:0.080498\n",
      "[1800]\tdtrain-mlogloss:0.080204\n",
      "[1900]\tdtrain-mlogloss:0.079911\n",
      "2 57.70462679862976\n",
      "[0]\tdtrain-mlogloss:1.25273\n",
      "[100]\tdtrain-mlogloss:0.101564\n",
      "[200]\tdtrain-mlogloss:0.094024\n",
      "[300]\tdtrain-mlogloss:0.090994\n",
      "[400]\tdtrain-mlogloss:0.08909\n",
      "[500]\tdtrain-mlogloss:0.087877\n",
      "[600]\tdtrain-mlogloss:0.086708\n",
      "[700]\tdtrain-mlogloss:0.085797\n",
      "[800]\tdtrain-mlogloss:0.085069\n",
      "[900]\tdtrain-mlogloss:0.084294\n",
      "[1000]\tdtrain-mlogloss:0.083707\n",
      "[1100]\tdtrain-mlogloss:0.083197\n",
      "[1200]\tdtrain-mlogloss:0.082742\n",
      "[1300]\tdtrain-mlogloss:0.082288\n",
      "[1400]\tdtrain-mlogloss:0.081935\n",
      "[1500]\tdtrain-mlogloss:0.081608\n",
      "[1600]\tdtrain-mlogloss:0.081284\n",
      "[1700]\tdtrain-mlogloss:0.080925\n",
      "[1800]\tdtrain-mlogloss:0.080568\n",
      "[1900]\tdtrain-mlogloss:0.080295\n",
      "3 57.00593185424805\n",
      "[0]\tdtrain-mlogloss:1.25268\n",
      "[100]\tdtrain-mlogloss:0.101528\n",
      "[200]\tdtrain-mlogloss:0.09411\n",
      "[300]\tdtrain-mlogloss:0.091101\n",
      "[400]\tdtrain-mlogloss:0.089268\n",
      "[500]\tdtrain-mlogloss:0.088029\n",
      "[600]\tdtrain-mlogloss:0.086907\n",
      "[700]\tdtrain-mlogloss:0.085962\n",
      "[800]\tdtrain-mlogloss:0.085085\n",
      "[900]\tdtrain-mlogloss:0.084375\n",
      "[1000]\tdtrain-mlogloss:0.083771\n",
      "[1100]\tdtrain-mlogloss:0.08317\n",
      "[1200]\tdtrain-mlogloss:0.082698\n",
      "[1300]\tdtrain-mlogloss:0.082195\n",
      "[1400]\tdtrain-mlogloss:0.081821\n",
      "[1500]\tdtrain-mlogloss:0.081484\n",
      "[1600]\tdtrain-mlogloss:0.081162\n",
      "[1700]\tdtrain-mlogloss:0.080867\n",
      "[1800]\tdtrain-mlogloss:0.080567\n",
      "[1900]\tdtrain-mlogloss:0.080276\n",
      "4 59.47738075256348\n",
      "[0]\tdtrain-mlogloss:1.25268\n",
      "[100]\tdtrain-mlogloss:0.101521\n",
      "[200]\tdtrain-mlogloss:0.09404\n",
      "[300]\tdtrain-mlogloss:0.091104\n",
      "[400]\tdtrain-mlogloss:0.089161\n",
      "[500]\tdtrain-mlogloss:0.087665\n",
      "[600]\tdtrain-mlogloss:0.086487\n",
      "[700]\tdtrain-mlogloss:0.085526\n",
      "[800]\tdtrain-mlogloss:0.084715\n",
      "[900]\tdtrain-mlogloss:0.084028\n",
      "[1000]\tdtrain-mlogloss:0.08341\n",
      "[1100]\tdtrain-mlogloss:0.082969\n",
      "[1200]\tdtrain-mlogloss:0.082498\n",
      "[1300]\tdtrain-mlogloss:0.082063\n",
      "[1400]\tdtrain-mlogloss:0.081718\n",
      "[1500]\tdtrain-mlogloss:0.08139\n",
      "[1600]\tdtrain-mlogloss:0.081099\n",
      "[1700]\tdtrain-mlogloss:0.080745\n",
      "[1800]\tdtrain-mlogloss:0.080475\n",
      "[1900]\tdtrain-mlogloss:0.08024\n",
      "5 57.45694708824158\n",
      "[0]\tdtrain-mlogloss:1.25266\n",
      "[100]\tdtrain-mlogloss:0.101471\n",
      "[200]\tdtrain-mlogloss:0.094073\n",
      "[300]\tdtrain-mlogloss:0.090869\n",
      "[400]\tdtrain-mlogloss:0.089055\n",
      "[500]\tdtrain-mlogloss:0.087677\n",
      "[600]\tdtrain-mlogloss:0.086535\n",
      "[700]\tdtrain-mlogloss:0.085599\n",
      "[800]\tdtrain-mlogloss:0.084881\n",
      "[900]\tdtrain-mlogloss:0.084243\n",
      "[1000]\tdtrain-mlogloss:0.083576\n",
      "[1100]\tdtrain-mlogloss:0.082994\n",
      "[1200]\tdtrain-mlogloss:0.082503\n",
      "[1300]\tdtrain-mlogloss:0.08205\n",
      "[1400]\tdtrain-mlogloss:0.081675\n",
      "[1500]\tdtrain-mlogloss:0.081373\n",
      "[1600]\tdtrain-mlogloss:0.081056\n",
      "[1700]\tdtrain-mlogloss:0.08076\n",
      "[1800]\tdtrain-mlogloss:0.08052\n",
      "[1900]\tdtrain-mlogloss:0.080241\n",
      "6 57.25143814086914\n",
      "[0]\tdtrain-mlogloss:1.25266\n",
      "[100]\tdtrain-mlogloss:0.101518\n",
      "[200]\tdtrain-mlogloss:0.093958\n",
      "[300]\tdtrain-mlogloss:0.090995\n",
      "[400]\tdtrain-mlogloss:0.089091\n",
      "[500]\tdtrain-mlogloss:0.087515\n",
      "[600]\tdtrain-mlogloss:0.086384\n",
      "[700]\tdtrain-mlogloss:0.085478\n",
      "[800]\tdtrain-mlogloss:0.08478\n",
      "[900]\tdtrain-mlogloss:0.08413\n",
      "[1000]\tdtrain-mlogloss:0.083575\n",
      "[1100]\tdtrain-mlogloss:0.083159\n",
      "[1200]\tdtrain-mlogloss:0.082713\n",
      "[1300]\tdtrain-mlogloss:0.082202\n",
      "[1400]\tdtrain-mlogloss:0.081828\n",
      "[1500]\tdtrain-mlogloss:0.08146\n",
      "[1600]\tdtrain-mlogloss:0.081111\n",
      "[1700]\tdtrain-mlogloss:0.080816\n",
      "[1800]\tdtrain-mlogloss:0.080521\n",
      "[1900]\tdtrain-mlogloss:0.080238\n",
      "7 58.04810833930969\n",
      "[0]\tdtrain-mlogloss:1.25274\n",
      "[100]\tdtrain-mlogloss:0.101487\n",
      "[200]\tdtrain-mlogloss:0.094036\n",
      "[300]\tdtrain-mlogloss:0.090954\n",
      "[400]\tdtrain-mlogloss:0.089066\n",
      "[500]\tdtrain-mlogloss:0.08768\n",
      "[600]\tdtrain-mlogloss:0.086548\n",
      "[700]\tdtrain-mlogloss:0.085763\n",
      "[800]\tdtrain-mlogloss:0.084998\n",
      "[900]\tdtrain-mlogloss:0.084306\n",
      "[1000]\tdtrain-mlogloss:0.083664\n",
      "[1100]\tdtrain-mlogloss:0.083204\n",
      "[1200]\tdtrain-mlogloss:0.082776\n",
      "[1300]\tdtrain-mlogloss:0.082364\n",
      "[1400]\tdtrain-mlogloss:0.08195\n",
      "[1500]\tdtrain-mlogloss:0.081619\n",
      "[1600]\tdtrain-mlogloss:0.081252\n",
      "[1700]\tdtrain-mlogloss:0.080978\n",
      "[1800]\tdtrain-mlogloss:0.080737\n",
      "[1900]\tdtrain-mlogloss:0.080487\n",
      "8 57.429518938064575\n",
      "[0]\tdtrain-mlogloss:1.25267\n",
      "[100]\tdtrain-mlogloss:0.101512\n",
      "[200]\tdtrain-mlogloss:0.094236\n",
      "[300]\tdtrain-mlogloss:0.090997\n",
      "[400]\tdtrain-mlogloss:0.089113\n",
      "[500]\tdtrain-mlogloss:0.087526\n",
      "[600]\tdtrain-mlogloss:0.086364\n",
      "[700]\tdtrain-mlogloss:0.08547\n",
      "[800]\tdtrain-mlogloss:0.084751\n",
      "[900]\tdtrain-mlogloss:0.084079\n",
      "[1000]\tdtrain-mlogloss:0.083572\n",
      "[1100]\tdtrain-mlogloss:0.083036\n",
      "[1200]\tdtrain-mlogloss:0.082604\n",
      "[1300]\tdtrain-mlogloss:0.082194\n",
      "[1400]\tdtrain-mlogloss:0.081832\n",
      "[1500]\tdtrain-mlogloss:0.081497\n",
      "[1600]\tdtrain-mlogloss:0.081168\n",
      "[1700]\tdtrain-mlogloss:0.080881\n",
      "[1800]\tdtrain-mlogloss:0.080624\n",
      "[1900]\tdtrain-mlogloss:0.08043\n",
      "9 60.24776744842529\n",
      "[0]\tdtrain-mlogloss:1.25266\n",
      "[100]\tdtrain-mlogloss:0.101522\n",
      "[200]\tdtrain-mlogloss:0.094127\n",
      "[300]\tdtrain-mlogloss:0.090909\n",
      "[400]\tdtrain-mlogloss:0.088983\n",
      "[500]\tdtrain-mlogloss:0.087725\n",
      "[600]\tdtrain-mlogloss:0.08651\n",
      "[700]\tdtrain-mlogloss:0.085485\n",
      "[800]\tdtrain-mlogloss:0.084667\n",
      "[900]\tdtrain-mlogloss:0.083987\n",
      "[1000]\tdtrain-mlogloss:0.083376\n",
      "[1100]\tdtrain-mlogloss:0.082855\n",
      "[1200]\tdtrain-mlogloss:0.082406\n",
      "[1300]\tdtrain-mlogloss:0.08194\n",
      "[1400]\tdtrain-mlogloss:0.081596\n",
      "[1500]\tdtrain-mlogloss:0.081243\n",
      "[1600]\tdtrain-mlogloss:0.080881\n",
      "[1700]\tdtrain-mlogloss:0.080605\n",
      "[1800]\tdtrain-mlogloss:0.080382\n",
      "[1900]\tdtrain-mlogloss:0.080108\n",
      "10 57.40758967399597\n",
      "[0]\tdtrain-mlogloss:1.25265\n",
      "[100]\tdtrain-mlogloss:0.101575\n",
      "[200]\tdtrain-mlogloss:0.094064\n",
      "[300]\tdtrain-mlogloss:0.0909\n",
      "[400]\tdtrain-mlogloss:0.089061\n",
      "[500]\tdtrain-mlogloss:0.087712\n",
      "[600]\tdtrain-mlogloss:0.086734\n",
      "[700]\tdtrain-mlogloss:0.085852\n",
      "[800]\tdtrain-mlogloss:0.085088\n",
      "[900]\tdtrain-mlogloss:0.084486\n",
      "[1000]\tdtrain-mlogloss:0.083897\n",
      "[1100]\tdtrain-mlogloss:0.083369\n",
      "[1200]\tdtrain-mlogloss:0.082847\n",
      "[1300]\tdtrain-mlogloss:0.082378\n",
      "[1400]\tdtrain-mlogloss:0.081968\n",
      "[1500]\tdtrain-mlogloss:0.081633\n",
      "[1600]\tdtrain-mlogloss:0.081311\n",
      "[1700]\tdtrain-mlogloss:0.080897\n",
      "[1800]\tdtrain-mlogloss:0.0806\n",
      "[1900]\tdtrain-mlogloss:0.080308\n",
      "11 56.68404817581177\n",
      "[0]\tdtrain-mlogloss:1.25273\n",
      "[100]\tdtrain-mlogloss:0.101467\n",
      "[200]\tdtrain-mlogloss:0.093979\n",
      "[300]\tdtrain-mlogloss:0.091069\n",
      "[400]\tdtrain-mlogloss:0.089226\n",
      "[500]\tdtrain-mlogloss:0.087848\n",
      "[600]\tdtrain-mlogloss:0.086683\n",
      "[700]\tdtrain-mlogloss:0.085792\n",
      "[800]\tdtrain-mlogloss:0.084938\n",
      "[900]\tdtrain-mlogloss:0.084302\n",
      "[1000]\tdtrain-mlogloss:0.083692\n",
      "[1100]\tdtrain-mlogloss:0.083116\n",
      "[1200]\tdtrain-mlogloss:0.082636\n",
      "[1300]\tdtrain-mlogloss:0.082213\n",
      "[1400]\tdtrain-mlogloss:0.081844\n",
      "[1500]\tdtrain-mlogloss:0.081486\n",
      "[1600]\tdtrain-mlogloss:0.081177\n",
      "[1700]\tdtrain-mlogloss:0.080862\n",
      "[1800]\tdtrain-mlogloss:0.080576\n",
      "[1900]\tdtrain-mlogloss:0.08035\n",
      "12 57.02772831916809\n",
      "[0]\tdtrain-mlogloss:1.25263\n",
      "[100]\tdtrain-mlogloss:0.101505\n",
      "[200]\tdtrain-mlogloss:0.093931\n",
      "[300]\tdtrain-mlogloss:0.090873\n",
      "[400]\tdtrain-mlogloss:0.08905\n",
      "[500]\tdtrain-mlogloss:0.087531\n",
      "[600]\tdtrain-mlogloss:0.086375\n",
      "[700]\tdtrain-mlogloss:0.085431\n",
      "[800]\tdtrain-mlogloss:0.084666\n",
      "[900]\tdtrain-mlogloss:0.08398\n",
      "[1000]\tdtrain-mlogloss:0.08338\n",
      "[1100]\tdtrain-mlogloss:0.082862\n",
      "[1200]\tdtrain-mlogloss:0.082432\n",
      "[1300]\tdtrain-mlogloss:0.082005\n",
      "[1400]\tdtrain-mlogloss:0.081604\n",
      "[1500]\tdtrain-mlogloss:0.081246\n",
      "[1600]\tdtrain-mlogloss:0.080966\n",
      "[1700]\tdtrain-mlogloss:0.080681\n",
      "[1800]\tdtrain-mlogloss:0.080348\n",
      "[1900]\tdtrain-mlogloss:0.080031\n",
      "13 57.30077528953552\n",
      "[0]\tdtrain-mlogloss:1.25262\n",
      "[100]\tdtrain-mlogloss:0.101517\n",
      "[200]\tdtrain-mlogloss:0.093948\n",
      "[300]\tdtrain-mlogloss:0.090925\n",
      "[400]\tdtrain-mlogloss:0.089112\n",
      "[500]\tdtrain-mlogloss:0.087795\n",
      "[600]\tdtrain-mlogloss:0.086504\n",
      "[700]\tdtrain-mlogloss:0.085609\n",
      "[800]\tdtrain-mlogloss:0.084815\n",
      "[900]\tdtrain-mlogloss:0.084037\n",
      "[1000]\tdtrain-mlogloss:0.083357\n",
      "[1100]\tdtrain-mlogloss:0.082833\n",
      "[1200]\tdtrain-mlogloss:0.082324\n",
      "[1300]\tdtrain-mlogloss:0.081762\n",
      "[1400]\tdtrain-mlogloss:0.081367\n",
      "[1500]\tdtrain-mlogloss:0.081023\n",
      "[1600]\tdtrain-mlogloss:0.080642\n",
      "[1700]\tdtrain-mlogloss:0.080319\n",
      "[1800]\tdtrain-mlogloss:0.080054\n",
      "[1900]\tdtrain-mlogloss:0.079747\n",
      "14 57.22449564933777\n",
      "[0]\tdtrain-mlogloss:1.25259\n",
      "[100]\tdtrain-mlogloss:0.101427\n",
      "[200]\tdtrain-mlogloss:0.094069\n",
      "[300]\tdtrain-mlogloss:0.09085\n",
      "[400]\tdtrain-mlogloss:0.088715\n",
      "[500]\tdtrain-mlogloss:0.087157\n",
      "[600]\tdtrain-mlogloss:0.086055\n",
      "[700]\tdtrain-mlogloss:0.085067\n",
      "[800]\tdtrain-mlogloss:0.084317\n",
      "[900]\tdtrain-mlogloss:0.083735\n",
      "[1000]\tdtrain-mlogloss:0.083016\n",
      "[1100]\tdtrain-mlogloss:0.082553\n",
      "[1200]\tdtrain-mlogloss:0.082173\n",
      "[1300]\tdtrain-mlogloss:0.081836\n",
      "[1400]\tdtrain-mlogloss:0.081545\n",
      "[1500]\tdtrain-mlogloss:0.081269\n",
      "[1600]\tdtrain-mlogloss:0.080967\n",
      "[1700]\tdtrain-mlogloss:0.08069\n",
      "[1800]\tdtrain-mlogloss:0.080481\n",
      "[1900]\tdtrain-mlogloss:0.080273\n",
      "15 56.71267342567444\n",
      "[0]\tdtrain-mlogloss:1.25263\n",
      "[100]\tdtrain-mlogloss:0.101531\n",
      "[200]\tdtrain-mlogloss:0.094043\n",
      "[300]\tdtrain-mlogloss:0.091102\n",
      "[400]\tdtrain-mlogloss:0.089289\n",
      "[500]\tdtrain-mlogloss:0.087844\n",
      "[600]\tdtrain-mlogloss:0.086571\n",
      "[700]\tdtrain-mlogloss:0.085633\n",
      "[800]\tdtrain-mlogloss:0.084884\n",
      "[900]\tdtrain-mlogloss:0.084227\n",
      "[1000]\tdtrain-mlogloss:0.083644\n",
      "[1100]\tdtrain-mlogloss:0.083171\n",
      "[1200]\tdtrain-mlogloss:0.08272\n",
      "[1300]\tdtrain-mlogloss:0.082292\n",
      "[1400]\tdtrain-mlogloss:0.081903\n",
      "[1500]\tdtrain-mlogloss:0.081606\n",
      "[1600]\tdtrain-mlogloss:0.081262\n",
      "[1700]\tdtrain-mlogloss:0.080939\n",
      "[1800]\tdtrain-mlogloss:0.080682\n",
      "[1900]\tdtrain-mlogloss:0.080367\n",
      "16 59.240684270858765\n",
      "[0]\tdtrain-mlogloss:1.25265\n",
      "[100]\tdtrain-mlogloss:0.101495\n",
      "[200]\tdtrain-mlogloss:0.094128\n",
      "[300]\tdtrain-mlogloss:0.090819\n",
      "[400]\tdtrain-mlogloss:0.088989\n",
      "[500]\tdtrain-mlogloss:0.087588\n",
      "[600]\tdtrain-mlogloss:0.086422\n",
      "[700]\tdtrain-mlogloss:0.085407\n",
      "[800]\tdtrain-mlogloss:0.084578\n",
      "[900]\tdtrain-mlogloss:0.083933\n",
      "[1000]\tdtrain-mlogloss:0.083309\n",
      "[1100]\tdtrain-mlogloss:0.082767\n",
      "[1200]\tdtrain-mlogloss:0.082316\n",
      "[1300]\tdtrain-mlogloss:0.081885\n",
      "[1400]\tdtrain-mlogloss:0.08156\n",
      "[1500]\tdtrain-mlogloss:0.081194\n",
      "[1600]\tdtrain-mlogloss:0.080906\n",
      "[1700]\tdtrain-mlogloss:0.080605\n",
      "[1800]\tdtrain-mlogloss:0.080326\n",
      "[1900]\tdtrain-mlogloss:0.080035\n",
      "17 56.93361139297485\n",
      "[0]\tdtrain-mlogloss:1.25265\n",
      "[100]\tdtrain-mlogloss:0.101473\n",
      "[200]\tdtrain-mlogloss:0.09398\n",
      "[300]\tdtrain-mlogloss:0.090857\n",
      "[400]\tdtrain-mlogloss:0.089074\n",
      "[500]\tdtrain-mlogloss:0.087614\n",
      "[600]\tdtrain-mlogloss:0.086457\n",
      "[700]\tdtrain-mlogloss:0.085515\n",
      "[800]\tdtrain-mlogloss:0.08478\n",
      "[900]\tdtrain-mlogloss:0.084049\n",
      "[1000]\tdtrain-mlogloss:0.083439\n",
      "[1100]\tdtrain-mlogloss:0.08293\n",
      "[1200]\tdtrain-mlogloss:0.082433\n",
      "[1300]\tdtrain-mlogloss:0.082008\n",
      "[1400]\tdtrain-mlogloss:0.081687\n",
      "[1500]\tdtrain-mlogloss:0.081281\n",
      "[1600]\tdtrain-mlogloss:0.08099\n",
      "[1700]\tdtrain-mlogloss:0.080623\n",
      "[1800]\tdtrain-mlogloss:0.080343\n",
      "[1900]\tdtrain-mlogloss:0.080088\n",
      "18 60.38389873504639\n",
      "[0]\tdtrain-mlogloss:1.25269\n",
      "[100]\tdtrain-mlogloss:0.101512\n",
      "[200]\tdtrain-mlogloss:0.094001\n",
      "[300]\tdtrain-mlogloss:0.090887\n",
      "[400]\tdtrain-mlogloss:0.088833\n",
      "[500]\tdtrain-mlogloss:0.087407\n",
      "[600]\tdtrain-mlogloss:0.086218\n",
      "[700]\tdtrain-mlogloss:0.085408\n",
      "[800]\tdtrain-mlogloss:0.084644\n",
      "[900]\tdtrain-mlogloss:0.083951\n",
      "[1000]\tdtrain-mlogloss:0.083438\n",
      "[1100]\tdtrain-mlogloss:0.0829\n",
      "[1200]\tdtrain-mlogloss:0.082501\n",
      "[1300]\tdtrain-mlogloss:0.082132\n",
      "[1400]\tdtrain-mlogloss:0.081753\n",
      "[1500]\tdtrain-mlogloss:0.081403\n",
      "[1600]\tdtrain-mlogloss:0.081078\n",
      "[1700]\tdtrain-mlogloss:0.080824\n",
      "[1800]\tdtrain-mlogloss:0.080554\n",
      "[1900]\tdtrain-mlogloss:0.080322\n",
      "19 57.07797050476074\n",
      "[0]\tdtrain-mlogloss:1.25269\n",
      "[100]\tdtrain-mlogloss:0.10156\n",
      "[200]\tdtrain-mlogloss:0.093807\n",
      "[300]\tdtrain-mlogloss:0.090916\n",
      "[400]\tdtrain-mlogloss:0.08901\n",
      "[500]\tdtrain-mlogloss:0.087618\n",
      "[600]\tdtrain-mlogloss:0.086521\n",
      "[700]\tdtrain-mlogloss:0.085589\n",
      "[800]\tdtrain-mlogloss:0.084859\n",
      "[900]\tdtrain-mlogloss:0.084145\n",
      "[1000]\tdtrain-mlogloss:0.083566\n",
      "[1100]\tdtrain-mlogloss:0.082991\n",
      "[1200]\tdtrain-mlogloss:0.082509\n",
      "[1300]\tdtrain-mlogloss:0.082068\n",
      "[1400]\tdtrain-mlogloss:0.08171\n",
      "[1500]\tdtrain-mlogloss:0.081374\n",
      "[1600]\tdtrain-mlogloss:0.08101\n",
      "[1700]\tdtrain-mlogloss:0.080622\n",
      "[1800]\tdtrain-mlogloss:0.080314\n",
      "[1900]\tdtrain-mlogloss:0.080042\n",
      "20 57.156821966171265\n",
      "[0]\tdtrain-mlogloss:1.25264\n",
      "[100]\tdtrain-mlogloss:0.101536\n",
      "[200]\tdtrain-mlogloss:0.094069\n",
      "[300]\tdtrain-mlogloss:0.090743\n",
      "[400]\tdtrain-mlogloss:0.088988\n",
      "[500]\tdtrain-mlogloss:0.087537\n",
      "[600]\tdtrain-mlogloss:0.086486\n",
      "[700]\tdtrain-mlogloss:0.085622\n",
      "[800]\tdtrain-mlogloss:0.084789\n",
      "[900]\tdtrain-mlogloss:0.084194\n",
      "[1000]\tdtrain-mlogloss:0.083519\n",
      "[1100]\tdtrain-mlogloss:0.08301\n",
      "[1200]\tdtrain-mlogloss:0.082582\n",
      "[1300]\tdtrain-mlogloss:0.082211\n",
      "[1400]\tdtrain-mlogloss:0.081825\n",
      "[1500]\tdtrain-mlogloss:0.081467\n",
      "[1600]\tdtrain-mlogloss:0.081119\n",
      "[1700]\tdtrain-mlogloss:0.080824\n",
      "[1800]\tdtrain-mlogloss:0.080539\n",
      "[1900]\tdtrain-mlogloss:0.080289\n",
      "21 56.95369625091553\n",
      "[0]\tdtrain-mlogloss:1.25269\n",
      "[100]\tdtrain-mlogloss:0.101592\n",
      "[200]\tdtrain-mlogloss:0.094035\n",
      "[300]\tdtrain-mlogloss:0.091007\n",
      "[400]\tdtrain-mlogloss:0.089171\n",
      "[500]\tdtrain-mlogloss:0.087757\n",
      "[600]\tdtrain-mlogloss:0.086684\n",
      "[700]\tdtrain-mlogloss:0.085641\n",
      "[800]\tdtrain-mlogloss:0.084829\n",
      "[900]\tdtrain-mlogloss:0.084137\n",
      "[1000]\tdtrain-mlogloss:0.083618\n",
      "[1100]\tdtrain-mlogloss:0.08306\n",
      "[1200]\tdtrain-mlogloss:0.082629\n",
      "[1300]\tdtrain-mlogloss:0.082189\n",
      "[1400]\tdtrain-mlogloss:0.08176\n",
      "[1500]\tdtrain-mlogloss:0.081362\n",
      "[1600]\tdtrain-mlogloss:0.081004\n",
      "[1700]\tdtrain-mlogloss:0.080785\n",
      "[1800]\tdtrain-mlogloss:0.08046\n",
      "[1900]\tdtrain-mlogloss:0.080154\n",
      "22 57.208534240722656\n",
      "[0]\tdtrain-mlogloss:1.25269\n",
      "[100]\tdtrain-mlogloss:0.10163\n",
      "[200]\tdtrain-mlogloss:0.094048\n",
      "[300]\tdtrain-mlogloss:0.090901\n",
      "[400]\tdtrain-mlogloss:0.089061\n",
      "[500]\tdtrain-mlogloss:0.087524\n",
      "[600]\tdtrain-mlogloss:0.08649\n",
      "[700]\tdtrain-mlogloss:0.085596\n",
      "[800]\tdtrain-mlogloss:0.084832\n",
      "[900]\tdtrain-mlogloss:0.084116\n",
      "[1000]\tdtrain-mlogloss:0.083551\n",
      "[1100]\tdtrain-mlogloss:0.08289\n",
      "[1200]\tdtrain-mlogloss:0.082403\n",
      "[1300]\tdtrain-mlogloss:0.081964\n",
      "[1400]\tdtrain-mlogloss:0.081564\n",
      "[1500]\tdtrain-mlogloss:0.081222\n",
      "[1600]\tdtrain-mlogloss:0.080878\n",
      "[1700]\tdtrain-mlogloss:0.080577\n",
      "[1800]\tdtrain-mlogloss:0.080285\n",
      "[1900]\tdtrain-mlogloss:0.080015\n",
      "23 57.322168827056885\n",
      "[0]\tdtrain-mlogloss:1.25259\n",
      "[100]\tdtrain-mlogloss:0.10141\n",
      "[200]\tdtrain-mlogloss:0.093885\n",
      "[300]\tdtrain-mlogloss:0.090934\n",
      "[400]\tdtrain-mlogloss:0.089096\n",
      "[500]\tdtrain-mlogloss:0.087853\n",
      "[600]\tdtrain-mlogloss:0.086705\n",
      "[700]\tdtrain-mlogloss:0.085804\n",
      "[800]\tdtrain-mlogloss:0.08489\n",
      "[900]\tdtrain-mlogloss:0.084219\n",
      "[1000]\tdtrain-mlogloss:0.083647\n",
      "[1100]\tdtrain-mlogloss:0.083144\n",
      "[1200]\tdtrain-mlogloss:0.08274\n",
      "[1300]\tdtrain-mlogloss:0.082283\n",
      "[1400]\tdtrain-mlogloss:0.081929\n",
      "[1500]\tdtrain-mlogloss:0.081527\n",
      "[1600]\tdtrain-mlogloss:0.081148\n",
      "[1700]\tdtrain-mlogloss:0.080859\n",
      "[1800]\tdtrain-mlogloss:0.080509\n",
      "[1900]\tdtrain-mlogloss:0.080245\n",
      "24 57.0718777179718\n",
      "[0]\tdtrain-mlogloss:1.25265\n",
      "[100]\tdtrain-mlogloss:0.101515\n",
      "[200]\tdtrain-mlogloss:0.094083\n",
      "[300]\tdtrain-mlogloss:0.091059\n",
      "[400]\tdtrain-mlogloss:0.089023\n",
      "[500]\tdtrain-mlogloss:0.087601\n",
      "[600]\tdtrain-mlogloss:0.086413\n",
      "[700]\tdtrain-mlogloss:0.085475\n",
      "[800]\tdtrain-mlogloss:0.084775\n",
      "[900]\tdtrain-mlogloss:0.084266\n",
      "[1000]\tdtrain-mlogloss:0.083667\n",
      "[1100]\tdtrain-mlogloss:0.083188\n",
      "[1200]\tdtrain-mlogloss:0.08271\n",
      "[1300]\tdtrain-mlogloss:0.082318\n",
      "[1400]\tdtrain-mlogloss:0.081911\n",
      "[1500]\tdtrain-mlogloss:0.081526\n",
      "[1600]\tdtrain-mlogloss:0.081226\n",
      "[1700]\tdtrain-mlogloss:0.080941\n",
      "[1800]\tdtrain-mlogloss:0.080607\n",
      "[1900]\tdtrain-mlogloss:0.080357\n",
      "25 58.1974995136261\n",
      "[0]\tdtrain-mlogloss:1.25266\n",
      "[100]\tdtrain-mlogloss:0.101541\n",
      "[200]\tdtrain-mlogloss:0.094053\n",
      "[300]\tdtrain-mlogloss:0.091023\n",
      "[400]\tdtrain-mlogloss:0.089065\n",
      "[500]\tdtrain-mlogloss:0.087594\n",
      "[600]\tdtrain-mlogloss:0.086396\n",
      "[700]\tdtrain-mlogloss:0.085491\n",
      "[800]\tdtrain-mlogloss:0.084666\n",
      "[900]\tdtrain-mlogloss:0.084007\n",
      "[1000]\tdtrain-mlogloss:0.083391\n",
      "[1100]\tdtrain-mlogloss:0.082894\n",
      "[1200]\tdtrain-mlogloss:0.082496\n",
      "[1300]\tdtrain-mlogloss:0.082099\n",
      "[1400]\tdtrain-mlogloss:0.081723\n",
      "[1500]\tdtrain-mlogloss:0.081356\n",
      "[1600]\tdtrain-mlogloss:0.081034\n",
      "[1700]\tdtrain-mlogloss:0.080679\n",
      "[1800]\tdtrain-mlogloss:0.080409\n",
      "[1900]\tdtrain-mlogloss:0.080155\n",
      "26 57.174638509750366\n",
      "[0]\tdtrain-mlogloss:1.25267\n",
      "[100]\tdtrain-mlogloss:0.101533\n",
      "[200]\tdtrain-mlogloss:0.093876\n",
      "[300]\tdtrain-mlogloss:0.090827\n",
      "[400]\tdtrain-mlogloss:0.089059\n",
      "[500]\tdtrain-mlogloss:0.087608\n",
      "[600]\tdtrain-mlogloss:0.086606\n",
      "[700]\tdtrain-mlogloss:0.085741\n",
      "[800]\tdtrain-mlogloss:0.085023\n",
      "[900]\tdtrain-mlogloss:0.084319\n",
      "[1000]\tdtrain-mlogloss:0.083709\n",
      "[1100]\tdtrain-mlogloss:0.083117\n",
      "[1200]\tdtrain-mlogloss:0.082646\n",
      "[1300]\tdtrain-mlogloss:0.082199\n",
      "[1400]\tdtrain-mlogloss:0.08182\n",
      "[1500]\tdtrain-mlogloss:0.081476\n",
      "[1600]\tdtrain-mlogloss:0.081149\n",
      "[1700]\tdtrain-mlogloss:0.080851\n",
      "[1800]\tdtrain-mlogloss:0.080532\n",
      "[1900]\tdtrain-mlogloss:0.080237\n",
      "27 56.867427110672\n",
      "[0]\tdtrain-mlogloss:1.25275\n",
      "[100]\tdtrain-mlogloss:0.101639\n",
      "[200]\tdtrain-mlogloss:0.094297\n",
      "[300]\tdtrain-mlogloss:0.090974\n",
      "[400]\tdtrain-mlogloss:0.08899\n",
      "[500]\tdtrain-mlogloss:0.0876\n",
      "[600]\tdtrain-mlogloss:0.086527\n",
      "[700]\tdtrain-mlogloss:0.085467\n",
      "[800]\tdtrain-mlogloss:0.084736\n",
      "[900]\tdtrain-mlogloss:0.084142\n",
      "[1000]\tdtrain-mlogloss:0.083559\n",
      "[1100]\tdtrain-mlogloss:0.083026\n",
      "[1200]\tdtrain-mlogloss:0.082618\n",
      "[1300]\tdtrain-mlogloss:0.082234\n",
      "[1400]\tdtrain-mlogloss:0.081845\n",
      "[1500]\tdtrain-mlogloss:0.081554\n",
      "[1600]\tdtrain-mlogloss:0.081179\n",
      "[1700]\tdtrain-mlogloss:0.080874\n",
      "[1800]\tdtrain-mlogloss:0.080605\n",
      "[1900]\tdtrain-mlogloss:0.080369\n",
      "28 58.568766832351685\n",
      "[0]\tdtrain-mlogloss:1.25267\n",
      "[100]\tdtrain-mlogloss:0.101528\n",
      "[200]\tdtrain-mlogloss:0.094032\n",
      "[300]\tdtrain-mlogloss:0.091048\n",
      "[400]\tdtrain-mlogloss:0.089282\n",
      "[500]\tdtrain-mlogloss:0.087762\n",
      "[600]\tdtrain-mlogloss:0.086665\n",
      "[700]\tdtrain-mlogloss:0.085868\n",
      "[800]\tdtrain-mlogloss:0.085049\n",
      "[900]\tdtrain-mlogloss:0.084398\n",
      "[1000]\tdtrain-mlogloss:0.083818\n",
      "[1100]\tdtrain-mlogloss:0.083168\n",
      "[1200]\tdtrain-mlogloss:0.082677\n",
      "[1300]\tdtrain-mlogloss:0.082208\n",
      "[1400]\tdtrain-mlogloss:0.081756\n",
      "[1500]\tdtrain-mlogloss:0.081472\n",
      "[1600]\tdtrain-mlogloss:0.081169\n",
      "[1700]\tdtrain-mlogloss:0.080927\n",
      "[1800]\tdtrain-mlogloss:0.080713\n",
      "[1900]\tdtrain-mlogloss:0.080422\n",
      "29 56.90070080757141\n",
      "[0]\tdtrain-mlogloss:1.25267\n",
      "[100]\tdtrain-mlogloss:0.101602\n",
      "[200]\tdtrain-mlogloss:0.094022\n",
      "[300]\tdtrain-mlogloss:0.091113\n",
      "[400]\tdtrain-mlogloss:0.089122\n",
      "[500]\tdtrain-mlogloss:0.087551\n",
      "[600]\tdtrain-mlogloss:0.086433\n",
      "[700]\tdtrain-mlogloss:0.085532\n",
      "[800]\tdtrain-mlogloss:0.08467\n",
      "[900]\tdtrain-mlogloss:0.084015\n",
      "[1000]\tdtrain-mlogloss:0.083464\n",
      "[1100]\tdtrain-mlogloss:0.082937\n",
      "[1200]\tdtrain-mlogloss:0.082474\n",
      "[1300]\tdtrain-mlogloss:0.082086\n",
      "[1400]\tdtrain-mlogloss:0.081668\n",
      "[1500]\tdtrain-mlogloss:0.081306\n",
      "[1600]\tdtrain-mlogloss:0.080929\n",
      "[1700]\tdtrain-mlogloss:0.080567\n",
      "[1800]\tdtrain-mlogloss:0.080301\n",
      "[1900]\tdtrain-mlogloss:0.080019\n",
      "30 57.61551642417908\n",
      "[0]\tdtrain-mlogloss:1.25271\n",
      "[100]\tdtrain-mlogloss:0.10148\n",
      "[200]\tdtrain-mlogloss:0.094111\n",
      "[300]\tdtrain-mlogloss:0.091124\n",
      "[400]\tdtrain-mlogloss:0.089133\n",
      "[500]\tdtrain-mlogloss:0.087756\n",
      "[600]\tdtrain-mlogloss:0.086669\n",
      "[700]\tdtrain-mlogloss:0.085641\n",
      "[800]\tdtrain-mlogloss:0.084809\n",
      "[900]\tdtrain-mlogloss:0.084214\n",
      "[1000]\tdtrain-mlogloss:0.083563\n",
      "[1100]\tdtrain-mlogloss:0.083096\n",
      "[1200]\tdtrain-mlogloss:0.082613\n",
      "[1300]\tdtrain-mlogloss:0.08224\n",
      "[1400]\tdtrain-mlogloss:0.081863\n",
      "[1500]\tdtrain-mlogloss:0.081467\n",
      "[1600]\tdtrain-mlogloss:0.081163\n",
      "[1700]\tdtrain-mlogloss:0.08083\n",
      "[1800]\tdtrain-mlogloss:0.08052\n",
      "[1900]\tdtrain-mlogloss:0.080261\n",
      "31 56.922122955322266\n",
      "[0]\tdtrain-mlogloss:1.25264\n",
      "[100]\tdtrain-mlogloss:0.101521\n",
      "[200]\tdtrain-mlogloss:0.094096\n",
      "[300]\tdtrain-mlogloss:0.091057\n",
      "[400]\tdtrain-mlogloss:0.089101\n",
      "[500]\tdtrain-mlogloss:0.087498\n",
      "[600]\tdtrain-mlogloss:0.086351\n",
      "[700]\tdtrain-mlogloss:0.085294\n",
      "[800]\tdtrain-mlogloss:0.084452\n",
      "[900]\tdtrain-mlogloss:0.083807\n",
      "[1000]\tdtrain-mlogloss:0.083315\n",
      "[1100]\tdtrain-mlogloss:0.08286\n",
      "[1200]\tdtrain-mlogloss:0.082403\n",
      "[1300]\tdtrain-mlogloss:0.081966\n",
      "[1400]\tdtrain-mlogloss:0.081565\n",
      "[1500]\tdtrain-mlogloss:0.081229\n",
      "[1600]\tdtrain-mlogloss:0.080858\n",
      "[1700]\tdtrain-mlogloss:0.080584\n",
      "[1800]\tdtrain-mlogloss:0.080313\n",
      "[1900]\tdtrain-mlogloss:0.080114\n",
      "32 57.24461555480957\n",
      "[0]\tdtrain-mlogloss:1.25265\n",
      "[100]\tdtrain-mlogloss:0.101557\n",
      "[200]\tdtrain-mlogloss:0.094061\n",
      "[300]\tdtrain-mlogloss:0.090943\n",
      "[400]\tdtrain-mlogloss:0.08924\n",
      "[500]\tdtrain-mlogloss:0.087769\n",
      "[600]\tdtrain-mlogloss:0.086574\n",
      "[700]\tdtrain-mlogloss:0.085614\n",
      "[800]\tdtrain-mlogloss:0.084753\n",
      "[900]\tdtrain-mlogloss:0.084018\n",
      "[1000]\tdtrain-mlogloss:0.083503\n",
      "[1100]\tdtrain-mlogloss:0.082955\n",
      "[1200]\tdtrain-mlogloss:0.082388\n",
      "[1300]\tdtrain-mlogloss:0.081971\n",
      "[1400]\tdtrain-mlogloss:0.081585\n",
      "[1500]\tdtrain-mlogloss:0.081229\n",
      "[1600]\tdtrain-mlogloss:0.080913\n",
      "[1700]\tdtrain-mlogloss:0.080612\n",
      "[1800]\tdtrain-mlogloss:0.0803\n",
      "[1900]\tdtrain-mlogloss:0.079959\n",
      "33 57.221800327301025\n",
      "[0]\tdtrain-mlogloss:1.25273\n",
      "[100]\tdtrain-mlogloss:0.101546\n",
      "[200]\tdtrain-mlogloss:0.094132\n",
      "[300]\tdtrain-mlogloss:0.090964\n",
      "[400]\tdtrain-mlogloss:0.089105\n",
      "[500]\tdtrain-mlogloss:0.087723\n",
      "[600]\tdtrain-mlogloss:0.086573\n",
      "[700]\tdtrain-mlogloss:0.085651\n",
      "[800]\tdtrain-mlogloss:0.084873\n",
      "[900]\tdtrain-mlogloss:0.084254\n",
      "[1000]\tdtrain-mlogloss:0.083743\n",
      "[1100]\tdtrain-mlogloss:0.083182\n",
      "[1200]\tdtrain-mlogloss:0.082717\n",
      "[1300]\tdtrain-mlogloss:0.082206\n",
      "[1400]\tdtrain-mlogloss:0.08182\n",
      "[1500]\tdtrain-mlogloss:0.08145\n",
      "[1600]\tdtrain-mlogloss:0.081131\n",
      "[1700]\tdtrain-mlogloss:0.080851\n",
      "[1800]\tdtrain-mlogloss:0.080587\n",
      "[1900]\tdtrain-mlogloss:0.08034\n",
      "34 57.28527855873108\n",
      "[0]\tdtrain-mlogloss:1.25263\n",
      "[100]\tdtrain-mlogloss:0.101509\n",
      "[200]\tdtrain-mlogloss:0.093901\n",
      "[300]\tdtrain-mlogloss:0.090958\n",
      "[400]\tdtrain-mlogloss:0.08909\n",
      "[500]\tdtrain-mlogloss:0.087668\n",
      "[600]\tdtrain-mlogloss:0.086438\n",
      "[700]\tdtrain-mlogloss:0.085389\n",
      "[800]\tdtrain-mlogloss:0.084475\n",
      "[900]\tdtrain-mlogloss:0.08382\n",
      "[1000]\tdtrain-mlogloss:0.083284\n",
      "[1100]\tdtrain-mlogloss:0.082696\n",
      "[1200]\tdtrain-mlogloss:0.082294\n",
      "[1300]\tdtrain-mlogloss:0.081937\n",
      "[1400]\tdtrain-mlogloss:0.081612\n",
      "[1500]\tdtrain-mlogloss:0.081309\n",
      "[1600]\tdtrain-mlogloss:0.080946\n",
      "[1700]\tdtrain-mlogloss:0.080632\n",
      "[1800]\tdtrain-mlogloss:0.080357\n",
      "[1900]\tdtrain-mlogloss:0.080107\n",
      "35 57.58305215835571\n",
      "[0]\tdtrain-mlogloss:1.25269\n",
      "[100]\tdtrain-mlogloss:0.101509\n",
      "[200]\tdtrain-mlogloss:0.094177\n",
      "[300]\tdtrain-mlogloss:0.09108\n",
      "[400]\tdtrain-mlogloss:0.089233\n",
      "[500]\tdtrain-mlogloss:0.087807\n",
      "[600]\tdtrain-mlogloss:0.086568\n",
      "[700]\tdtrain-mlogloss:0.08569\n",
      "[800]\tdtrain-mlogloss:0.084932\n",
      "[900]\tdtrain-mlogloss:0.08419\n",
      "[1000]\tdtrain-mlogloss:0.083539\n",
      "[1100]\tdtrain-mlogloss:0.082975\n",
      "[1200]\tdtrain-mlogloss:0.082582\n",
      "[1300]\tdtrain-mlogloss:0.082138\n",
      "[1400]\tdtrain-mlogloss:0.081678\n",
      "[1500]\tdtrain-mlogloss:0.081361\n",
      "[1600]\tdtrain-mlogloss:0.080991\n",
      "[1700]\tdtrain-mlogloss:0.080707\n",
      "[1800]\tdtrain-mlogloss:0.080412\n",
      "[1900]\tdtrain-mlogloss:0.080124\n",
      "36 57.723814725875854\n",
      "[0]\tdtrain-mlogloss:1.25265\n",
      "[100]\tdtrain-mlogloss:0.101458\n",
      "[200]\tdtrain-mlogloss:0.093987\n",
      "[300]\tdtrain-mlogloss:0.090882\n",
      "[400]\tdtrain-mlogloss:0.0891\n",
      "[500]\tdtrain-mlogloss:0.087897\n",
      "[600]\tdtrain-mlogloss:0.086771\n",
      "[700]\tdtrain-mlogloss:0.085806\n",
      "[800]\tdtrain-mlogloss:0.084987\n",
      "[900]\tdtrain-mlogloss:0.084265\n",
      "[1000]\tdtrain-mlogloss:0.083654\n",
      "[1100]\tdtrain-mlogloss:0.083174\n",
      "[1200]\tdtrain-mlogloss:0.082704\n",
      "[1300]\tdtrain-mlogloss:0.082294\n",
      "[1400]\tdtrain-mlogloss:0.081848\n",
      "[1500]\tdtrain-mlogloss:0.08149\n",
      "[1600]\tdtrain-mlogloss:0.081142\n",
      "[1700]\tdtrain-mlogloss:0.080772\n",
      "[1800]\tdtrain-mlogloss:0.080474\n",
      "[1900]\tdtrain-mlogloss:0.080224\n",
      "37 59.12208914756775\n",
      "[0]\tdtrain-mlogloss:1.25265\n",
      "[100]\tdtrain-mlogloss:0.101538\n",
      "[200]\tdtrain-mlogloss:0.094155\n",
      "[300]\tdtrain-mlogloss:0.091032\n",
      "[400]\tdtrain-mlogloss:0.089088\n",
      "[500]\tdtrain-mlogloss:0.08762\n",
      "[600]\tdtrain-mlogloss:0.086449\n",
      "[700]\tdtrain-mlogloss:0.085584\n",
      "[800]\tdtrain-mlogloss:0.084709\n",
      "[900]\tdtrain-mlogloss:0.083943\n",
      "[1000]\tdtrain-mlogloss:0.083281\n",
      "[1100]\tdtrain-mlogloss:0.082728\n",
      "[1200]\tdtrain-mlogloss:0.082261\n",
      "[1300]\tdtrain-mlogloss:0.081816\n",
      "[1400]\tdtrain-mlogloss:0.081449\n",
      "[1500]\tdtrain-mlogloss:0.081079\n",
      "[1600]\tdtrain-mlogloss:0.080826\n",
      "[1700]\tdtrain-mlogloss:0.080542\n",
      "[1800]\tdtrain-mlogloss:0.080235\n",
      "[1900]\tdtrain-mlogloss:0.079976\n",
      "38 57.63083600997925\n",
      "[0]\tdtrain-mlogloss:1.25263\n",
      "[100]\tdtrain-mlogloss:0.101549\n",
      "[200]\tdtrain-mlogloss:0.094085\n",
      "[300]\tdtrain-mlogloss:0.09112\n",
      "[400]\tdtrain-mlogloss:0.089226\n",
      "[500]\tdtrain-mlogloss:0.087926\n",
      "[600]\tdtrain-mlogloss:0.086879\n",
      "[700]\tdtrain-mlogloss:0.085977\n",
      "[800]\tdtrain-mlogloss:0.085273\n",
      "[900]\tdtrain-mlogloss:0.084622\n",
      "[1000]\tdtrain-mlogloss:0.083994\n",
      "[1100]\tdtrain-mlogloss:0.083402\n",
      "[1200]\tdtrain-mlogloss:0.082883\n",
      "[1300]\tdtrain-mlogloss:0.082406\n",
      "[1400]\tdtrain-mlogloss:0.081985\n",
      "[1500]\tdtrain-mlogloss:0.081598\n",
      "[1600]\tdtrain-mlogloss:0.081205\n",
      "[1700]\tdtrain-mlogloss:0.0808\n",
      "[1800]\tdtrain-mlogloss:0.080463\n",
      "[1900]\tdtrain-mlogloss:0.080248\n",
      "39 58.77335810661316\n",
      "[0]\tdtrain-mlogloss:1.25273\n",
      "[100]\tdtrain-mlogloss:0.101615\n",
      "[200]\tdtrain-mlogloss:0.094249\n",
      "[300]\tdtrain-mlogloss:0.091213\n",
      "[400]\tdtrain-mlogloss:0.089111\n",
      "[500]\tdtrain-mlogloss:0.087652\n",
      "[600]\tdtrain-mlogloss:0.086526\n",
      "[700]\tdtrain-mlogloss:0.085559\n",
      "[800]\tdtrain-mlogloss:0.08488\n",
      "[900]\tdtrain-mlogloss:0.084175\n",
      "[1000]\tdtrain-mlogloss:0.083527\n",
      "[1100]\tdtrain-mlogloss:0.083007\n",
      "[1200]\tdtrain-mlogloss:0.08256\n",
      "[1300]\tdtrain-mlogloss:0.082115\n",
      "[1400]\tdtrain-mlogloss:0.081699\n",
      "[1500]\tdtrain-mlogloss:0.081347\n",
      "[1600]\tdtrain-mlogloss:0.081003\n",
      "[1700]\tdtrain-mlogloss:0.080708\n",
      "[1800]\tdtrain-mlogloss:0.080362\n",
      "[1900]\tdtrain-mlogloss:0.080067\n",
      "40 57.80456066131592\n",
      "[0]\tdtrain-mlogloss:1.25268\n",
      "[100]\tdtrain-mlogloss:0.101348\n",
      "[200]\tdtrain-mlogloss:0.09394\n",
      "[300]\tdtrain-mlogloss:0.090944\n",
      "[400]\tdtrain-mlogloss:0.088992\n",
      "[500]\tdtrain-mlogloss:0.08757\n",
      "[600]\tdtrain-mlogloss:0.086452\n",
      "[700]\tdtrain-mlogloss:0.085412\n",
      "[800]\tdtrain-mlogloss:0.084607\n",
      "[900]\tdtrain-mlogloss:0.083903\n",
      "[1000]\tdtrain-mlogloss:0.083348\n",
      "[1100]\tdtrain-mlogloss:0.082871\n",
      "[1200]\tdtrain-mlogloss:0.082397\n",
      "[1300]\tdtrain-mlogloss:0.08197\n",
      "[1400]\tdtrain-mlogloss:0.081588\n",
      "[1500]\tdtrain-mlogloss:0.081246\n",
      "[1600]\tdtrain-mlogloss:0.080946\n",
      "[1700]\tdtrain-mlogloss:0.080626\n",
      "[1800]\tdtrain-mlogloss:0.080278\n",
      "[1900]\tdtrain-mlogloss:0.080057\n",
      "41 58.08836531639099\n",
      "[0]\tdtrain-mlogloss:1.2527\n",
      "[100]\tdtrain-mlogloss:0.101496\n",
      "[200]\tdtrain-mlogloss:0.094085\n",
      "[300]\tdtrain-mlogloss:0.090917\n",
      "[400]\tdtrain-mlogloss:0.089004\n",
      "[500]\tdtrain-mlogloss:0.087649\n",
      "[600]\tdtrain-mlogloss:0.086564\n",
      "[700]\tdtrain-mlogloss:0.085708\n",
      "[800]\tdtrain-mlogloss:0.084914\n",
      "[900]\tdtrain-mlogloss:0.084264\n",
      "[1000]\tdtrain-mlogloss:0.083639\n",
      "[1100]\tdtrain-mlogloss:0.083087\n",
      "[1200]\tdtrain-mlogloss:0.08264\n",
      "[1300]\tdtrain-mlogloss:0.082252\n",
      "[1400]\tdtrain-mlogloss:0.081887\n",
      "[1500]\tdtrain-mlogloss:0.081552\n",
      "[1600]\tdtrain-mlogloss:0.081193\n",
      "[1700]\tdtrain-mlogloss:0.080842\n",
      "[1800]\tdtrain-mlogloss:0.080489\n",
      "[1900]\tdtrain-mlogloss:0.080226\n",
      "42 58.9461350440979\n",
      "[0]\tdtrain-mlogloss:1.25261\n",
      "[100]\tdtrain-mlogloss:0.101442\n",
      "[200]\tdtrain-mlogloss:0.093838\n",
      "[300]\tdtrain-mlogloss:0.091035\n",
      "[400]\tdtrain-mlogloss:0.089187\n",
      "[500]\tdtrain-mlogloss:0.087818\n",
      "[600]\tdtrain-mlogloss:0.086752\n",
      "[700]\tdtrain-mlogloss:0.085712\n",
      "[800]\tdtrain-mlogloss:0.084883\n",
      "[900]\tdtrain-mlogloss:0.084087\n",
      "[1000]\tdtrain-mlogloss:0.083413\n",
      "[1100]\tdtrain-mlogloss:0.082871\n",
      "[1200]\tdtrain-mlogloss:0.082399\n",
      "[1300]\tdtrain-mlogloss:0.081997\n",
      "[1400]\tdtrain-mlogloss:0.081601\n",
      "[1500]\tdtrain-mlogloss:0.081229\n",
      "[1600]\tdtrain-mlogloss:0.080884\n",
      "[1700]\tdtrain-mlogloss:0.080531\n",
      "[1800]\tdtrain-mlogloss:0.080316\n",
      "[1900]\tdtrain-mlogloss:0.080054\n",
      "43 57.66601061820984\n",
      "[0]\tdtrain-mlogloss:1.25263\n",
      "[100]\tdtrain-mlogloss:0.101427\n",
      "[200]\tdtrain-mlogloss:0.093959\n",
      "[300]\tdtrain-mlogloss:0.090981\n",
      "[400]\tdtrain-mlogloss:0.089031\n",
      "[500]\tdtrain-mlogloss:0.087462\n",
      "[600]\tdtrain-mlogloss:0.086314\n",
      "[700]\tdtrain-mlogloss:0.085307\n",
      "[800]\tdtrain-mlogloss:0.084552\n",
      "[900]\tdtrain-mlogloss:0.083814\n",
      "[1000]\tdtrain-mlogloss:0.083252\n",
      "[1100]\tdtrain-mlogloss:0.082709\n",
      "[1200]\tdtrain-mlogloss:0.082337\n",
      "[1300]\tdtrain-mlogloss:0.081986\n",
      "[1400]\tdtrain-mlogloss:0.081636\n",
      "[1500]\tdtrain-mlogloss:0.081319\n",
      "[1600]\tdtrain-mlogloss:0.080988\n",
      "[1700]\tdtrain-mlogloss:0.080693\n",
      "[1800]\tdtrain-mlogloss:0.080453\n",
      "[1900]\tdtrain-mlogloss:0.080243\n",
      "44 59.84544229507446\n",
      "[0]\tdtrain-mlogloss:1.25265\n",
      "[100]\tdtrain-mlogloss:0.101466\n",
      "[200]\tdtrain-mlogloss:0.093744\n",
      "[300]\tdtrain-mlogloss:0.090815\n",
      "[400]\tdtrain-mlogloss:0.088924\n",
      "[500]\tdtrain-mlogloss:0.087451\n",
      "[600]\tdtrain-mlogloss:0.086328\n",
      "[700]\tdtrain-mlogloss:0.085497\n",
      "[800]\tdtrain-mlogloss:0.084608\n",
      "[900]\tdtrain-mlogloss:0.084012\n",
      "[1000]\tdtrain-mlogloss:0.083505\n",
      "[1100]\tdtrain-mlogloss:0.083011\n",
      "[1200]\tdtrain-mlogloss:0.08255\n",
      "[1300]\tdtrain-mlogloss:0.082064\n",
      "[1400]\tdtrain-mlogloss:0.081708\n",
      "[1500]\tdtrain-mlogloss:0.081346\n",
      "[1600]\tdtrain-mlogloss:0.081025\n",
      "[1700]\tdtrain-mlogloss:0.080699\n",
      "[1800]\tdtrain-mlogloss:0.080403\n",
      "[1900]\tdtrain-mlogloss:0.08017\n",
      "45 57.4298837184906\n",
      "[0]\tdtrain-mlogloss:1.25264\n",
      "[100]\tdtrain-mlogloss:0.10149\n",
      "[200]\tdtrain-mlogloss:0.093933\n",
      "[300]\tdtrain-mlogloss:0.090977\n",
      "[400]\tdtrain-mlogloss:0.089145\n",
      "[500]\tdtrain-mlogloss:0.087675\n",
      "[600]\tdtrain-mlogloss:0.086486\n",
      "[700]\tdtrain-mlogloss:0.085436\n",
      "[800]\tdtrain-mlogloss:0.084765\n",
      "[900]\tdtrain-mlogloss:0.084018\n",
      "[1000]\tdtrain-mlogloss:0.083347\n",
      "[1100]\tdtrain-mlogloss:0.082884\n",
      "[1200]\tdtrain-mlogloss:0.082451\n",
      "[1300]\tdtrain-mlogloss:0.081999\n",
      "[1400]\tdtrain-mlogloss:0.081615\n",
      "[1500]\tdtrain-mlogloss:0.081243\n",
      "[1600]\tdtrain-mlogloss:0.08091\n",
      "[1700]\tdtrain-mlogloss:0.080614\n",
      "[1800]\tdtrain-mlogloss:0.080372\n",
      "[1900]\tdtrain-mlogloss:0.08016\n",
      "46 57.3707799911499\n",
      "[0]\tdtrain-mlogloss:1.25261\n",
      "[100]\tdtrain-mlogloss:0.101555\n",
      "[200]\tdtrain-mlogloss:0.094087\n",
      "[300]\tdtrain-mlogloss:0.091039\n",
      "[400]\tdtrain-mlogloss:0.089029\n",
      "[500]\tdtrain-mlogloss:0.08763\n",
      "[600]\tdtrain-mlogloss:0.086543\n",
      "[700]\tdtrain-mlogloss:0.085526\n",
      "[800]\tdtrain-mlogloss:0.084784\n",
      "[900]\tdtrain-mlogloss:0.084071\n",
      "[1000]\tdtrain-mlogloss:0.083389\n",
      "[1100]\tdtrain-mlogloss:0.082891\n",
      "[1200]\tdtrain-mlogloss:0.082415\n",
      "[1300]\tdtrain-mlogloss:0.081944\n",
      "[1400]\tdtrain-mlogloss:0.081556\n",
      "[1500]\tdtrain-mlogloss:0.081165\n",
      "[1600]\tdtrain-mlogloss:0.080864\n",
      "[1700]\tdtrain-mlogloss:0.080579\n",
      "[1800]\tdtrain-mlogloss:0.080316\n",
      "[1900]\tdtrain-mlogloss:0.080087\n",
      "47 59.1281955242157\n",
      "[0]\tdtrain-mlogloss:1.25265\n",
      "[100]\tdtrain-mlogloss:0.101535\n",
      "[200]\tdtrain-mlogloss:0.093881\n",
      "[300]\tdtrain-mlogloss:0.090833\n",
      "[400]\tdtrain-mlogloss:0.089151\n",
      "[500]\tdtrain-mlogloss:0.087758\n",
      "[600]\tdtrain-mlogloss:0.086614\n",
      "[700]\tdtrain-mlogloss:0.085648\n",
      "[800]\tdtrain-mlogloss:0.084884\n",
      "[900]\tdtrain-mlogloss:0.084306\n",
      "[1000]\tdtrain-mlogloss:0.083618\n",
      "[1100]\tdtrain-mlogloss:0.083142\n",
      "[1200]\tdtrain-mlogloss:0.08267\n",
      "[1300]\tdtrain-mlogloss:0.082327\n",
      "[1400]\tdtrain-mlogloss:0.081938\n",
      "[1500]\tdtrain-mlogloss:0.081655\n",
      "[1600]\tdtrain-mlogloss:0.08132\n",
      "[1700]\tdtrain-mlogloss:0.081012\n",
      "[1800]\tdtrain-mlogloss:0.080689\n",
      "[1900]\tdtrain-mlogloss:0.080424\n",
      "48 57.58799982070923\n",
      "[0]\tdtrain-mlogloss:1.25263\n",
      "[100]\tdtrain-mlogloss:0.101356\n",
      "[200]\tdtrain-mlogloss:0.093906\n",
      "[300]\tdtrain-mlogloss:0.090923\n",
      "[400]\tdtrain-mlogloss:0.089004\n",
      "[500]\tdtrain-mlogloss:0.087508\n",
      "[600]\tdtrain-mlogloss:0.08631\n",
      "[700]\tdtrain-mlogloss:0.085434\n",
      "[800]\tdtrain-mlogloss:0.084684\n",
      "[900]\tdtrain-mlogloss:0.084108\n",
      "[1000]\tdtrain-mlogloss:0.083497\n",
      "[1100]\tdtrain-mlogloss:0.082921\n",
      "[1200]\tdtrain-mlogloss:0.082501\n",
      "[1300]\tdtrain-mlogloss:0.082063\n",
      "[1400]\tdtrain-mlogloss:0.081665\n",
      "[1500]\tdtrain-mlogloss:0.0813\n",
      "[1600]\tdtrain-mlogloss:0.080964\n",
      "[1700]\tdtrain-mlogloss:0.080654\n",
      "[1800]\tdtrain-mlogloss:0.080428\n",
      "[1900]\tdtrain-mlogloss:0.08017\n",
      "49 57.549768686294556\n",
      "[0]\tdtrain-mlogloss:1.25262\n",
      "[100]\tdtrain-mlogloss:0.101387\n",
      "[200]\tdtrain-mlogloss:0.093912\n",
      "[300]\tdtrain-mlogloss:0.090879\n",
      "[400]\tdtrain-mlogloss:0.089067\n",
      "[500]\tdtrain-mlogloss:0.087622\n",
      "[600]\tdtrain-mlogloss:0.086422\n",
      "[700]\tdtrain-mlogloss:0.085492\n",
      "[800]\tdtrain-mlogloss:0.084714\n",
      "[900]\tdtrain-mlogloss:0.084094\n",
      "[1000]\tdtrain-mlogloss:0.083552\n",
      "[1100]\tdtrain-mlogloss:0.083046\n",
      "[1200]\tdtrain-mlogloss:0.082549\n",
      "[1300]\tdtrain-mlogloss:0.082156\n",
      "[1400]\tdtrain-mlogloss:0.081785\n",
      "[1500]\tdtrain-mlogloss:0.081457\n",
      "[1600]\tdtrain-mlogloss:0.081145\n",
      "[1700]\tdtrain-mlogloss:0.080829\n",
      "[1800]\tdtrain-mlogloss:0.080535\n",
      "[1900]\tdtrain-mlogloss:0.080268\n",
      "50 57.64383292198181\n"
     ]
    }
   ],
   "source": [
    "preds_price = np.zeros( (len(test), 4) )\n",
    "count = 1\n",
    "for s in np.random.randint(0, 1000000, size=50):\n",
    "    params['seed'] = s\n",
    "    t1= time.time()\n",
    "    clf_xgb_main = xgb.train(dtrain=dtrain, params=params, num_boost_round=num_rounds, \\\n",
    "                             evals=watchlist,verbose_eval= 100)\n",
    "    preds_price += clf_xgb_main.predict(dtest)\n",
    "    print (count, time.time() - t1)\n",
    "    count = count +1\n",
    "preds_price = preds_price/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write submission file and submit\n",
    "columns = ['Front','Left','Rear','Right']\n",
    "sub = pd.DataFrame(data=preds_price, columns=columns)\n",
    "sub['Id'] = ids\n",
    "sub = sub[['Id','Front','Left','Rear','Right']]\n",
    "sub.to_csv(\"sub_xgboost_factor_ffeat_20June.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
